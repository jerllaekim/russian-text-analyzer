import streamlit as st
import re
import os
import json
import pandas as pd
from pymystem3 import Mystem
from google import genai
from google.cloud import vision 
import io
import urllib.parse 
import struct # WAV í—¤ë” ìƒì„±ì„ ìœ„í•´ ì¶”ê°€
from base64 import b64decode # Base64 ë””ì½”ë”©ì„ ìœ„í•´ ì¶”ê°€
from typing import Union # Python ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
import time # ì¬ì‹œë„ ì§€ì—°ì„ ìœ„í•´ ì¶”ê°€

# ---------------------- 0. ì´ˆê¸° ì„¤ì • ë° ì„¸ì…˜ ìƒíƒœ ----------------------

NEW_DEFAULT_TEXT = """ĞœĞĞ™ Ğ ĞĞ‘ĞĞ§Ğ˜Ğ™ Ğ”Ğ•ĞĞ¬
(Ğ Ğ°ÑÑĞºĞ°Ğ· ÑĞ¿Ğ¾Ğ½ÑĞºĞ¾Ğ³Ğ¾ Ğ±Ğ°Ğ½ĞºĞ¸Ñ€Ğ°)
Ğ Ğ°Ğ·Ñ€ĞµÑˆĞ¸Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒcÑ. ĞœĞµĞ½Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ Ğ¢Ğ°ĞºĞµÑˆĞ¸ ĞÑĞ°Ğ´Ğ°. Ğ¯ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ Ğ² Ğ±Ğ°Ğ½ĞºĞµ Â«Ğ¡Ğ°ĞºÑƒÑ€Ğ°Â». Ğ¯ Ğ¶Ğ¸Ğ²Ñƒ Ğ½ĞµĞ´Ğ°Ğ»ĞµĞºĞ¾ Ğ¾Ñ‚ Ğ¢Ğ¾ĞºĞ¸Ğ¾, Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ² Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğµ Ğ´Ğ½Ğ¸ Ñ Ğ²ÑÑ‚Ğ°Ñ Ğ² 5 Ñ‡Ğ°ÑĞ¾Ğ² ÑƒÑ‚Ñ€Ğ°, ÑƒĞ¼Ñ‹Ğ²Ğ°ÑÑÑŒ, Ğ¾Ğ´ĞµĞ²Ğ°ÑÑÑŒ, Ğ·Ğ°Ğ²Ñ‚Ñ€Ğ°ĞºĞ°Ñ Ğ¸ Ğ¸Ğ´Ñƒ Ğ½Ğ° ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ñ. ĞĞ° ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ğ¸ Ñ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ ÑĞ²ĞµĞ¶ÑƒÑ Ğ³Ğ°Ğ·ĞµÑ‚Ñƒ. Ğ¯ ĞµĞ´Ñƒ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğ° ÑĞ»ĞµĞºÑ‚Ñ€Ğ¸Ñ‡ĞºĞµ. Ğ’ ÑĞ»ĞµĞºÑ‚Ñ€Ğ¸Ñ‡ĞºĞµ Ñ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ñ‡Ğ¸Ñ‚Ğ°Ñ Ğ¸Ğ»Ğ¸ ÑĞ¿Ğ»Ñ. Ğ”Ğ¾Ñ€Ğ¾Ğ³Ğ° Ğ¾Ñ‚ Ğ´Ğ¾Ğ¼Ğ° Ğ´Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ 2 Ñ‡Ğ°ÑĞ°.
Ğ‘Ğ°Ğ½Ğº Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ² 8 ÑƒÑ‚Ñ€Ğ°, Ğ° Ğ·Ğ°ĞºĞ°Ğ½Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ² 8 Ğ²ĞµÑ‡ĞµÑ€Ğ°, Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ Ğ¼Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ Ğ´ĞµĞ½ÑŒ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµÑ‚ÑÑ 12 Ñ‡Ğ°ÑĞ¾Ğ², Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ 2 Ğ¿ĞµÑ€ĞµÑ€Ñ‹Ğ²Ğ°. Ğ Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ Ğ´ĞµĞ½ÑŒ Ğ´Ğ»Ñ Ğ¶ĞµĞ½Ñ‰Ğ¸Ğ½, ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ğ¾, Ğ¼ĞµĞ½ÑŒÑˆĞµ.
Ğ’ 8:30 Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ ÑĞ¾Ğ±Ñ€Ğ°Ğ½Ğ¸Ğµ, Ğ³Ğ´Ğµ Ğ¼Ñ‹ Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°ĞµĞ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºÑƒÑ ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸Ñ, ĞºÑƒÑ€Ñ Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€Ğ°, Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸, Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğ° Ğ´ĞµĞ½ÑŒ. ĞŸĞ¾Ñ‚Ğ¾Ğ¼ Ñ Ñ‡Ğ¸Ñ‚Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹, Ñ€ĞµÑˆĞ°Ñ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ÑÑÑŒ Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸, Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°Ñ Ğ¸Ğ¼ ÑÑ‡Ñ‘Ñ‚ Ğ² Ğ±Ğ°Ğ½ĞºĞµ, Ğ´Ğ°Ñ Ğ¸Ğ¼ ĞºÑ€ĞµĞ´Ğ¸Ñ‚, Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ°Ñ€Ğ¸Ğ²Ğ°Ñ Ğ¿Ğ¾ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ñƒ Ğ¸ Ñ‚Ğ°Ğº Ğ´Ğ°Ğ»ĞµĞµ.
ĞŸĞ¾ÑĞ»Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ÑÑÑŒ Ğ´Ğ¾Ğ¼Ğ¾Ğ¹. Ğ¢Ğ°Ğº ĞºĞ°Ğº Ñ Ğ¾Ñ‡ĞµĞ½ÑŒ ÑƒÑÑ‚Ğ°Ñ, Ğ´Ğ¾Ğ¼Ğ° Ñ ÑÑ€Ğ°Ğ·Ñƒ Ğ»Ğ¾Ğ¶ÑƒÑÑŒ ÑĞ¿Ğ°Ñ‚ÑŒ."""

DEFAULT_TEST_TEXT = "Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ ÑƒĞ»Ğ¸Ñ†Ğµ. Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°. Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾. Ğ¯ Ñ‡Ğ°ÑÑ‚Ğ¾ Ñ‡Ğ¸Ñ‚Ğ°Ñ ÑÑ‚Ñƒ ĞºĞ½Ğ¸Ğ³Ñƒ."


st.set_page_config(page_title="ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°", layout="wide")
st.title("ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°") 

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "selected_words" not in st.session_state:
    st.session_state.selected_words = []
if "clicked_word" not in st.session_state:
    st.session_state.clicked_word = None
if "word_info" not in st.session_state:
    st.session_state.word_info = {}
if "current_search_query" not in st.session_state:
    st.session_state.current_search_query = ""
if "ocr_output_text" not in st.session_state:
    st.session_state.ocr_output_text = ""
if "input_text_area" not in st.session_state:
    st.session_state.input_text_area = DEFAULT_TEST_TEXT
if "translated_text" not in st.session_state:
    st.session_state.translated_text = ""
if "last_processed_text" not in st.session_state:
    st.session_state.last_processed_text = "" 
if "last_processed_query" not in st.session_state:
    st.session_state.last_processed_query = ""
if "tts_audio" not in st.session_state: # TTS ì˜¤ë””ì˜¤ ì €ì¥
    st.session_state.tts_audio = None
if "tts_text_key" not in st.session_state: # TTS ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ì¼ì¹˜ í™•ì¸ìš©
    st.session_state.tts_text_key = ""


mystem = Mystem()

# ---------------------- í’ˆì‚¬ ë³€í™˜ ë”•ì…”ë„ˆë¦¬ ë° Mystem í•¨ìˆ˜ ----------------------
POS_MAP = {
    'S': 'ëª…ì‚¬', 'V': 'ë™ì‚¬', 'A': 'í˜•ìš©ì‚¬', 'ADV': 'ë¶€ì‚¬', 'PR': 'ì „ì¹˜ì‚¬',
    'CONJ': 'ì ‘ì†ì‚¬', 'INTJ': 'ê°íƒ„ì‚¬', 'PART': 'ë¶ˆë³€í™”ì‚¬', 'NUM': 'ìˆ˜ì‚¬',
    'APRO': 'ëŒ€ëª…ì‚¬ì  í˜•ìš©ì‚¬', 'ANUM': 'ì„œìˆ˜ì‚¬', 'SPRO': 'ëŒ€ëª…ì‚¬',
}

@st.cache_data(show_spinner=False)
def lemmatize_ru(word: str) -> str:
    if ' ' in word.strip():
        return word.strip()
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        lemmas = mystem.lemmatize(word)
        return (lemmas[0] if lemmas else word).strip()
    return word

@st.cache_data(show_spinner=False)
def get_pos_ru(word: str) -> str:
    if ' ' in word.strip():
        return 'ê´€ìš©êµ¬'
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        analysis = mystem.analyze(word)
        if analysis and 'analysis' in analysis[0] and analysis[0]['analysis']:
            grammar_info = analysis[0]['analysis'][0]['gr']
            pos_abbr = grammar_info.split('=')[0].split(',')[0].strip()
            return POS_MAP.get(pos_abbr, 'í’ˆì‚¬')
    return 'í’ˆì‚¬'

# ---------------------- OCR í•¨ìˆ˜ ----------------------
@st.cache_data(show_spinner="ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘")
def detect_text_from_image(image_bytes):
    try:
        if st.secrets.get("GCP_SA_KEY"):
            with open("temp_sa_key.json", "w") as f:
                json.dump(st.secrets["GCP_SA_KEY"], f)
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "temp_sa_key.json"
        elif "GOOGLE_APPLICATION_CREDENTIALS" not in os.environ:
            return "OCR API í‚¤(GOOGLE_APPLICATION_CREDENTIALS)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Cloud Vision API ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

        client = vision.ImageAnnotatorClient()
        image = vision.Image(content=image_bytes)
        response = client.text_detection(image=image)
        texts = response.text
            
        if response.error.message:
            return f"Vision API ì˜¤ë¥˜: {response.error.message}"
            
        return texts.split('\n', 1)[0] if texts else "ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    except Exception as e:
        return f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# ---------------------- TTS WAV ë³€í™˜ í•¨ìˆ˜ ----------------------

def pcm_to_wav(pcm_data: bytes, sample_rate: int) -> bytes:
    """Converts raw 16-bit PCM data to a WAV file format.
    Assumes 1 channel, 16-bit depth (2 bytes per sample).
    """
    channels = 1
    sample_width = 2
    
    # RIFF header
    chunk_id = b'RIFF'
    chunk_size = 36 + len(pcm_data)
    format_type = b'WAVE'

    # fmt sub-chunk
    sub_chunk1_id = b'fmt '
    sub_chunk1_size = 16  # PCM
    audio_format = 1  # PCM
    byte_rate = sample_rate * channels * sample_width
    block_align = channels * sample_width
    bits_per_sample = 16

    # data sub-chunk
    sub_chunk2_id = b'data'
    sub_chunk2_size = len(pcm_data)

    wav_header = struct.pack(
        '<4sI4s'  # RIFF header
        '4sIHHIIHH'  # fmt sub-chunk
        '4sIHHIIHH'  # fmt sub-chunk
        '4sI',  # data sub-chunk
        chunk_id, chunk_size, format_type,
        sub_chunk1_id, sub_chunk1_size, audio_format, channels, sample_rate, byte_rate, block_align, bits_per_sample,
        sub_chunk2_id, sub_chunk2_size
    )

    return wav_header + pcm_data

# ---------------------- 1. Gemini ì—°ë™ í•¨ìˆ˜ (ê¸°ì¡´) ----------------------

def get_gemini_client():
    api_key = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY"))
    return genai.Client(api_key=api_key) if api_key else None

@st.cache_data(show_spinner=False)
def fetch_from_gemini(word, lemma, pos):
    client = get_gemini_client()
    if not client:
        return {"ko_meanings": [f"'{word}'ì˜ API í‚¤ ì—†ìŒ (GEMINI_API_KEY ì„¤ì • í•„ìš”)"], "examples": []}
    
    SYSTEM_PROMPT = "ë„ˆëŠ” ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ í•™ìŠµ ë„ìš°ë¯¸ì´ë‹¤. ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´ì— ëŒ€í•´ ê°„ë‹¨í•œ í•œêµ­ì–´ ëœ»ê³¼ ì˜ˆë¬¸ì„ ìµœëŒ€ ë‘ ê°œë§Œ ì œê³µí•œë‹¤. í•œêµ­ì–´ ëœ»ì„ ì œê³µí•  ë•Œ ê²© ì •ë³´, ë¬¸ë²• ì •ë³´ ë“± ë¶ˆí•„ìš”í•œ ë¶€ê°€ ì •ë³´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤. ë§Œì•½ ë™ì‚¬(V)ì´ë©´, ë¶ˆì™„ë£Œìƒ(imp)ê³¼ ì™„ë£Œìƒ(perf) í˜•íƒœë¥¼ í•¨ê»˜ ì œê³µí•´ì•¼ í•œë‹¤. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤."
    
    if pos == 'ë™ì‚¬':
        prompt = f"""{SYSTEM_PROMPT}
ë‹¨ì–´: {word}
ê¸°ë³¸í˜•: {lemma}
{{ "ko_meanings": ["ëœ»1", "ëœ»2"], "aspect_pair": {{"imp": "ë¶ˆì™„ë£Œìƒ ë™ì‚¬", "perf": "ì™„ë£Œìƒ ë™ì‚¬"}}, "examples": [ {{"ru": "ì˜ˆë¬¸1", "ko": "ë²ˆì—­1"}}, {{"ru": "ì˜ˆë¬¸2", "ko": "ë²ˆì—­2"}} ] }}
"""
    else:
        prompt = f"""{SYSTEM_PROMPT}
ë‹¨ì–´: {word}
ê¸°ë³¸í˜•: {lemma}
{{ "ko_meanings": ["ëœ»1", "ëœ»2"], "examples": [ {{"ru": "ì˜ˆë¬¸1", "ko": "ë²ˆì—­1"}}, {{"ru": "ì˜ˆë¬¸2", "ko": "ë²ˆì—­2"}} ] }}
"""
    
    res = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
    text = res.text.strip()
    
    try:
        # JSON íŒŒì‹± ë¡œì§
        if text.startswith("```"):
            text = text.strip("`")
            lines = text.splitlines()
            if lines and lines[0].lower().startswith("json"):
                text = "\n".join(lines[1:])
            elif lines:
                text = "\n".join(lines)
                
        start_index = text.find('{')
        end_index = text.rfind('}')
        
        if start_index != -1 and end_index != -1 and end_index > start_index:
            json_text = text[start_index : end_index + 1]
        else:
            json_text = text
            
        data = json.loads(json_text)
        
        if 'examples' in data and len(data['examples']) > 2:
            data['examples'] = data['examples'][:2]
        return data
        
    except json.JSONDecodeError:
        return {"ko_meanings": ["JSON íŒŒì‹± ì˜¤ë¥˜"], "examples": []}


# ---------------------- 2. TTS í•¨ìˆ˜ (ì‹ ê·œ) ----------------------

def fetch_tts_audio(russian_text: str) -> Union[bytes, str]:
    client = get_gemini_client()
    if not client:
        return "Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ TTSë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì‚¬ìš©í•  ìŒì„± ì„¤ì • (KoreëŠ” ë§‘ê³  ë‹¨ë‹¨í•œ ëª©ì†Œë¦¬)
    TTS_VOICE = "Kore" 
    MAX_RETRIES = 3 # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    
    # í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ê¸¸ì´ ì œí•œ (ëª¨ë¸ ì˜¤ë¥˜ ë°©ì§€)
    # 1. íŠ¹ìˆ˜ ë¬¸ì ì œê±° (ëŸ¬ì‹œì•„ì–´ ì•ŒíŒŒë²³, ìˆ«ì, ê³µë°±, ê¸°ë³¸ êµ¬ë‘ì ë§Œ ë‚¨ê¹€)
    clean_text = re.sub(r'[^Ğ°-ÑĞ-Ğ¯Ñ‘Ğa-zA-Z0-9\s.,;?!:\-â€”()Â«Â»]', '', russian_text) 
    # 2. ì—¬ëŸ¬ ì¤„ë°”ê¿ˆ/ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()

    # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (TTS API íš¨ìœ¨ ë° ë¹„ìš© ê³ ë ¤)
    if len(clean_text) > 500:
        clean_text = clean_text[:500] + "..."
    
    # ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸: í…ìŠ¤íŠ¸ ìì²´ë§Œ ì „ë‹¬
    TTS_PROMPT = clean_text 

    payload = {
        "contents": [{
            # ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¡œ ì¸ì‹í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ í…ìŠ¤íŠ¸ íŒŒíŠ¸ë¡œ ì „ë‹¬
            "parts": [{"text": TTS_PROMPT}] 
        }],
        "generationConfig": {
            "responseModalities": ["AUDIO"],
            "speechConfig": {
                "voiceConfig": {
                    "prebuiltVoiceConfig": {"voiceName": TTS_VOICE}
                }
            }
        },
    }

    # API í˜¸ì¶œ ë° ì¬ì‹œë„ ë¡œì§
    for attempt in range(MAX_RETRIES):
        try:
            with st.spinner(f"ìŒì„± íŒŒì¼ ìƒì„± ì¤‘... (ì‹œë„ {attempt + 1}/{MAX_RETRIES})"):
                response = client.models.generate_content(
                    model="gemini-2.5-flash-preview-tts", 
                    contents=payload['contents'],
                    config=payload['generationConfig']
                )

            # ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬
            if not response.candidates or not response.candidates[0].content.parts:
                if attempt < MAX_RETRIES - 1:
                    time.sleep(2 ** attempt) # ì§€ìˆ˜ ë°±ì˜¤í”„
                    continue
                return "TTS API ì˜¤ë¥˜: ìœ íš¨í•œ ì‘ë‹µ êµ¬ì¡°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í›„ë³´ ë˜ëŠ” íŒŒíŠ¸ ëˆ„ë½)"

            audio_part = response.candidates[0].content.parts[0]
            
            # ì˜¤ë””ì˜¤ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ ê²€ì‚¬
            if hasattr(audio_part, 'inlineData') and audio_part.inlineData and audio_part.inlineData.data:
                # ì„±ê³µì ìœ¼ë¡œ ë°ì´í„° íšë“
                base64_data = audio_part.inlineData.data
                mime_type_full = audio_part.inlineData.mimeType
                
                # ìƒ˜í”Œ ë ˆì´íŠ¸ ì¶”ì¶œ (ê¸°ë³¸ 24000Hz)
                rate_match = re.search(r'rate=(\d+)', mime_type_full)
                sample_rate = int(rate_match.group(1)) if rate_match else 24000 

                # Base64 ë””ì½”ë”© ë° WAV ë³€í™˜
                pcm_data = b64decode(base64_data)
                wav_bytes = pcm_to_wav(pcm_data, sample_rate)
                
                return wav_bytes # ì„±ê³µ ì‹œ í•¨ìˆ˜ ì¢…ë£Œ

            # ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ëˆ„ë½ë˜ì—ˆìœ¼ë‚˜ ì¬ì‹œë„ íšŸìˆ˜ê°€ ë‚¨ì•˜ì„ ê²½ìš°
            if attempt < MAX_RETRIES - 1:
                time.sleep(2 ** attempt) # ì§€ìˆ˜ ë°±ì˜¤í”„
                continue
            
            # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ í›„ ìµœì¢… ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
            if hasattr(audio_part, 'text') and audio_part.text:
                 return f"TTS API ì˜¤ë¥˜: ì˜¤ë””ì˜¤ ë°ì´í„° ëˆ„ë½. ëŒ€ì‹  í…ìŠ¤íŠ¸ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤: '{audio_part.text[:100]}...'"
            
            return "TTS API ì˜¤ë¥˜: ìŒì„± ë°ì´í„°(inlineData.data)ê°€ ì‘ë‹µì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ë‚´ìš©ì´ë‚˜ API ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."

        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                time.sleep(2 ** attempt) # ì§€ìˆ˜ ë°±ì˜¤í”„
                continue
            # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ í›„ ìµœì¢… ì˜ˆì™¸ ë©”ì‹œì§€ ë°˜í™˜
            return f"TTS ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}"
    
    # for ë£¨í”„ê°€ ëë‚¬ìœ¼ë‚˜ (ë„ë‹¬í•  ìˆ˜ ì—†ì§€ë§Œ ë°©ì–´ì ìœ¼ë¡œ ì¶”ê°€)
    return "TTS API ì˜¤ë¥˜: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼"


# ---------------------- 3. í…ìŠ¤íŠ¸ ë²ˆì—­ í•¨ìˆ˜ (ê¸°ì¡´) ----------------------

@st.cache_data(show_spinner="í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì¤‘...")
def translate_text(russian_text, highlight_words):
    client = get_gemini_client()
    if not client:
        return "Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë²ˆì—­ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    phrases_to_highlight = ", ".join([f"'{w}'" for w in highlight_words])
    
    SYSTEM_INSTRUCTION = '''ë„ˆëŠ” ë²ˆì—­ê°€ì´ë‹¤. ìš”ì²­ëœ ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë§¥ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³ , ì ˆëŒ€ë¡œ ë‹¤ë¥¸ ì„¤ëª…, ì˜µì…˜, ì§ˆë¬¸, ë¶€ê°€ì ì¸ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤. ì˜¤ì§ ìµœì¢… ë²ˆì—­ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•œë‹¤.'''

    if phrases_to_highlight:
        translation_prompt = f"""
        **ë°˜ë“œì‹œ ì•„ë˜ ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´/êµ¬ì˜ í•œêµ­ì–´ ë²ˆì—­ì´ ë“±ì¥í•˜ë©´, ê·¸ í•œêµ­ì–´ ë²ˆì—­ ë‹¨ì–´/êµ¬ë¥¼ `<PHRASE_START>`ì™€ `<PHRASE_END>` ë§ˆí¬ì—…ìœ¼ë¡œ ê°ì‹¸ì•¼ í•´.**

        ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸: '{russian_text}'
        ë§ˆí¬ì—… ëŒ€ìƒ ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´/êµ¬: {phrases_to_highlight}
        """
    else:
        translation_prompt = f"ì›ë³¸ ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸: '{russian_text}'"

    try:
        res = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=translation_prompt,
            config={"system_instruction": SYSTEM_INSTRUCTION}
        )
        translated = res.text.strip()
        
        # í›„ì²˜ë¦¬: ë§ˆí¬ì—…ì„ HTML Span íƒœê·¸ë¡œ ë³€í™˜
        selected_class = "word-selected"
        translated = translated.replace("<PHRASE_START>", f'<span class="{selected_class}">')
        translated = translated.replace("<PHRASE_END>", '</span>')

        return translated

    except Exception as e:
        return f"ë²ˆì—­ ì˜¤ë¥˜ ë°œìƒ: {e}"


# ---------------------- 4. ì „ì—­ ìŠ¤íƒ€ì¼ ì •ì˜ ----------------------

st.markdown("""
<style>
    /* í…ìŠ¤íŠ¸ ì˜ì—­ ê°€ë…ì„± */
    .text-container {
        line-height: 2.0;
        margin-bottom: 20px;
        font-size: 1.25em;
    }
    /* ì„ íƒ/ê²€ìƒ‰ëœ ë‹¨ì–´/êµ¬ í•˜ì´ë¼ì´íŒ… + ë°‘ì¤„ */
    .word-selected {
        color: #007bff !important; 
        font-weight: bold;
        background-color: #e0f0ff; 
        padding: 2px 0px;
        border-bottom: 3px solid #007bff; 
        border-radius: 2px;
    }
    .search-link-container {
        display: flex;
        gap: 10px;
        margin-top: 15px;
        flex-wrap: wrap;
    }
    /* ğŸŒŸ ë²„íŠ¼ ìŠ¤íƒ€ì¼: ê¸°ë³¸ Streamlit ë²„íŠ¼ê³¼ ìœ ì‚¬í•˜ê²Œ ì„¤ì • (ë°ì€ íšŒìƒ‰) */
    .stButton>button {
        background-color: #f0f2f6;
        color: #333;
        border: 1px solid #ccc;
        border-radius: 0.5rem;
    }
    .stButton>button:hover {
        background-color: #e8e8e8;
        border-color: #aaa;
    }
</style>
""", unsafe_allow_html=True)


# ğŸŒŸ 5. ë²„íŠ¼ í´ë¦­ ì‹œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ëŠ” ì½œë°± í•¨ìˆ˜ ì •ì˜
def load_default_text():
    """
    NEW_DEFAULT_TEXTë¥¼ st.session_state.input_text_areaì— ë°˜ì˜í•˜ê³  
    ë¶„ì„ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    """
    st.session_state.input_text_area = NEW_DEFAULT_TEXT 
    st.session_state.translated_text = ""
    st.session_state.selected_words = []
    st.session_state.clicked_word = None
    st.session_state.word_info = {}
    st.session_state.current_search_query = ""
    st.session_state.last_processed_query = ""
    st.session_state.tts_audio = None # TTS ìƒíƒœ ì´ˆê¸°í™”
    st.session_state.tts_text_key = "" # TTS ìƒíƒœ ì´ˆê¸°í™”

# ğŸŒŸ 6. í•˜ì´ë¼ì´íŒ… ë¡œì§ í•¨ìˆ˜ ì •ì˜ 
def get_highlighted_html(text_to_process, highlight_words):
    selected_class = "word-selected"
    display_html = text_to_process
    
    highlight_candidates = sorted(
        [word for word in highlight_words if word.strip()],
        key=len,
        reverse=True
    )

    for phrase in highlight_candidates:
        escaped_phrase = re.escape(phrase)
        
        if ' ' in phrase:
            # êµ¬(Phrase) ê²€ìƒ‰
            display_html = re.sub(
                f'({escaped_phrase})', 
                f'<span class="{selected_class}">\\1</span>', 
                display_html
            )
        else:
            # ë‹¨ì–´(Word) ê²€ìƒ‰ (\bëŠ” ë‹¨ì–´ ê²½ê³„)
            pattern = re.compile(r'\b' + escaped_phrase + r'\b')
            display_html = pattern.sub(
                f'<span class="{selected_class}">{phrase}</span>', 
                display_html
            )
    
    return f'<div class="text-container">{display_html}</div>'


# ---------------------- 7. UI ë°°ì¹˜ ë° ë©”ì¸ ë¡œì§ ----------------------

# --- 7.1. OCR ë° í…ìŠ¤íŠ¸ ì…ë ¥ ì„¹ì…˜ ---
st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ(ì—…ë°ì´íŠ¸ ì˜ˆì •)")
uploaded_file = st.file_uploader("JPG, PNG ë“± ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image_bytes = uploaded_file.getvalue()
    ocr_result = detect_text_from_image(image_bytes)
    
    if ocr_result and not ocr_result.startswith(("OCR API í‚¤", "Vision API ì˜¤ë¥˜")):
        st.session_state.ocr_output_text = ocr_result
        st.session_state.input_text_area = ocr_result
        st.session_state.translated_text = ""
        st.success("ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
    else:
        st.error(ocr_result)

# í…ìŠ¤íŠ¸ ë°˜ì˜ ë²„íŠ¼ ì¶”ê°€
st.button(
    "ğŸ“š ì¤‘ê¸‰ëŸ¬ì‹œì•„ì–´ì—°ìŠµ í…ìŠ¤íŠ¸ ë°˜ì˜í•˜ê¸°", 
    on_click=load_default_text, 
    help="êµì¬ ì—°ìŠµìš© í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ì°½ì— ë°˜ì˜í•©ë‹ˆë‹¤."
)

st.subheader("ğŸ“ ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸") 
current_text = st.text_area(
    "ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìœ„ì— ì—…ë¡œë“œëœ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”", 
    value=st.session_state.input_text_area, 
    height=150, 
    key="input_text_area"
)


# í…ìŠ¤íŠ¸ê°€ ìˆ˜ì •ë˜ë©´ ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ë²ˆì—­/ë¶„ì„ ìƒíƒœ ì´ˆê¸°í™”
if current_text != st.session_state.last_processed_text:
    st.session_state.translated_text = ""
    st.session_state.selected_words = []
    st.session_state.clicked_word = None
    st.session_state.word_info = {}
    st.session_state.current_search_query = ""
    st.session_state.tts_audio = None
    st.session_state.tts_text_key = ""

# --- 7.2. ë‹¨ì–´ ê²€ìƒ‰ì°½ ë° ë¡œì§ ---
st.divider()
st.subheader("ğŸ” ë‹¨ì–´/êµ¬ ê²€ìƒ‰") 
manual_input = st.text_input("ë‹¨ì–´ ë˜ëŠ” êµ¬ë¥¼ ì…ë ¥í•˜ê³  Enter (ì˜ˆ: 'Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ ÑƒĞ»Ğ¸Ñ†Ğµ')", key="current_search_query")

if manual_input and manual_input != st.session_state.get("last_processed_query"):
    if manual_input not in st.session_state.selected_words:
        st.session_state.selected_words.append(manual_input)
    
    st.session_state.clicked_word = manual_input
    
    with st.spinner(f"'{manual_input}'ì— ëŒ€í•œ ì •ë³´ ë¶„ì„ ì¤‘..."):
        clean_input = manual_input
        lemma = lemmatize_ru(clean_input)
        pos = get_pos_ru(clean_input) 
        try:
            info = fetch_from_gemini(clean_input, lemma, pos)
            # ê¸°ë³¸í˜•(lemma) ê¸°ì¤€ìœ¼ë¡œ ì •ë³´ ì €ì¥. ë‹¨, í˜„ì¬ ê²€ìƒ‰ì–´(token)ê°€ ë‹¤ë¥´ë©´ ì—…ë°ì´íŠ¸
            if lemma not in st.session_state.word_info or st.session_state.word_info.get(lemma, {}).get('loaded_token') != clean_input:
                st.session_state.word_info[lemma] = {**info, "loaded_token": clean_input, "pos": pos}  
        except Exception as e:
            st.error(f"Gemini ì˜¤ë¥˜: {e}")
            
    st.session_state.last_processed_query = manual_input 

st.markdown("---") 


# ---------------------- 8. í…ìŠ¤íŠ¸ í•˜ì´ë¼ì´íŒ… ë° ìƒì„¸ ì •ë³´ ë ˆì´ì•„ì›ƒ ----------------------

left, right = st.columns([2, 1])


with left:
    st.subheader("ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ì›ë¬¸")
    
    # --- TTS ë²„íŠ¼ ë° ê°•ì„¸ ë§í¬ ---
    col_tts, col_accent = st.columns([1, 2])
    
    with col_tts:
        if st.button("â–¶ï¸ í…ìŠ¤íŠ¸ ìŒì„± ë“£ê¸° (TTS)", key="tts_button"):
            tts_result = fetch_tts_audio(current_text)
            
            if isinstance(tts_result, bytes):
                st.session_state.tts_audio = tts_result
                st.session_state.tts_text_key = current_text
                st.rerun() # ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì¦‰ì‹œ í‘œì‹œë¥¼ ìœ„í•´ ì¬ì‹¤í–‰
            else:
                st.error(tts_result)

    with col_accent:
        ACCENT_ONLINE_URL = "[https://russiangram.com/](https://russiangram.com/)"
        st.link_button(
            "ğŸ”Š ê°•ì„¸ í‘œì‹œ ì‚¬ì´íŠ¸ë¡œ ì´ë™ (russiangram.com)", 
            url=ACCENT_ONLINE_URL, 
            help="ìƒˆ íƒ­ìœ¼ë¡œ russiangram.comì´ ì—´ë¦½ë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì–´ ê°•ì„¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        )
        st.info("â¬†ï¸ ê°•ì„¸ í™•ì¸ì„ ìœ„í•´ ìƒˆ íƒ­ìœ¼ë¡œ russiangram.comì´ ì—´ë¦½ë‹ˆë‹¤. TTS ë²„íŠ¼ìœ¼ë¡œ ìŒì„±ë„ ë“¤ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


    # ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ í‘œì‹œ (TTS ë²„íŠ¼ í´ë¦­ í›„ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìˆê³  í…ìŠ¤íŠ¸ê°€ ì¼ì¹˜í•  ë•Œë§Œ)
    if 'tts_audio' in st.session_state and st.session_state.tts_audio and st.session_state.tts_text_key == current_text:
        st.audio(st.session_state.tts_audio, format='audio/wav', key='audio_playback')
        

    # ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ í•˜ì´ë¼ì´íŒ… ì¶œë ¥ (current_text ì‚¬ìš©)
    ru_html = get_highlighted_html(current_text, st.session_state.selected_words)
    st.markdown(ru_html, unsafe_allow_html=True)
    
    # ì´ˆê¸°í™” ë²„íŠ¼
    def reset_all_state():
        st.session_state.selected_words = []
        st.session_state.clicked_word = None
        st.session_state.word_info = {}
        st.session_state.current_search_query = ""
        st.session_state.input_text_area = DEFAULT_TEST_TEXT
        st.session_state.ocr_output_text = ""
        st.session_state.translated_text = ""
        st.session_state.last_processed_text = ""
        st.session_state.tts_audio = None
        st.session_state.tts_text_key = ""


    st.markdown("---")
    st.button("ğŸ”„ ì„ íƒ ë° ê²€ìƒ‰ ì´ˆê¸°í™”", key="reset_button", on_click=reset_all_state)
    

# --- 8.2. ë‹¨ì–´ ìƒì„¸ ì •ë³´ (right ì»¬ëŸ¼) + ê²€ìƒ‰ ë§í¬ ì¶”ê°€ ---
with right:
    st.subheader("ë‹¨ì–´ ìƒì„¸ ì •ë³´")
    
    current_token = st.session_state.clicked_word
    
    if current_token:
        clean_token = current_token
        lemma = lemmatize_ru(clean_token)
        info = st.session_state.word_info.get(lemma, {})

        if info and "ko_meanings" in info:
            pos = info.get("pos", "í’ˆì‚¬") 
            aspect_pair = info.get("aspect_pair") 
            
            st.markdown(f"### **{clean_token}**") 
            
            if pos == 'ë™ì‚¬' and aspect_pair:
                st.markdown(f"**ê¸°ë³¸í˜• (ë¶ˆì™„ë£Œìƒ):** *{aspect_pair.get('imp', lemma)}*")
                st.markdown(f"**ì™„ë£Œìƒ:** *{aspect_pair.get('perf', 'ì •ë³´ ì—†ìŒ')}*")
                st.markdown(f"**í’ˆì‚¬:** {pos}")
            elif pos == 'ê´€ìš©êµ¬':
                st.markdown(f"**êµ¬(å¥) í˜•íƒœ:** *{lemma}*")
                st.markdown(f"**í’ˆì‚¬:** {pos}")
            else:
                st.markdown(f"**ê¸°ë³¸í˜• (Lemma):** *{lemma}* ({pos})")
            
            st.divider()

            ko_meanings = info.get("ko_meanings", [])
            examples = info.get("examples", [])

            if ko_meanings:
                st.markdown("#### í•œêµ­ì–´ ëœ»")
                for m in ko_meanings:
                    st.markdown(f"- **{m}**")

            if examples:
                st.markdown("#### ğŸ“– ì˜ˆë¬¸")
                for ex in examples:
                    st.markdown(f"- {ex.get('ru', '')}")
                    st.markdown(f"â€ƒâ†’ {ex.get('ko', '')}")
            else:
                if ko_meanings and ko_meanings[0].startswith(f"'{current_token}'ì˜ API í‚¤ ì—†ìŒ"):
                    st.warning("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì˜ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                elif ko_meanings and ko_meanings[0] == "JSON íŒŒì‹± ì˜¤ë¥˜":
                    st.error("Gemini API ì •ë³´ ì˜¤ë¥˜.")
                else:
                    st.info("ì˜ˆë¬¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # --- ì™¸ë¶€ ê²€ìƒ‰ ë§í¬ ì¶”ê°€ ---
            encoded_query = urllib.parse.quote(clean_token)
            
            multitran_url = f"[https://www.multitran.com/m.exe?s=](https://www.multitran.com/m.exe?s=){encoded_query}&l1=1&l2=2"
            corpus_url = f"[http://search.ruscorpora.ru/search.xml?text=](http://search.ruscorpora.ru/search.xml?text=){encoded_query}&env=alpha&mode=main&sort=gr_tagging&lang=ru&nodia=1"
            
            st.markdown("#### ğŸŒ ì™¸ë¶€ ê²€ìƒ‰")
            col1, col2 = st.columns(2)
            with col1:
                st.link_button("ğŸ“š Multitran ê²€ìƒ‰", url=multitran_url)
            with col2:
                st.link_button("ğŸ“– êµ­ë¦½ ì½”í¼ìŠ¤ ê²€ìƒ‰", url=corpus_url)
            
        else:
            st.warning("ë‹¨ì–´ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì´ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            
    else:
        st.info("ê²€ìƒ‰ì°½ì— ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ë©´ ì—¬ê¸°ì— ìƒì„¸ ì •ë³´ê°€ í‘œì‹œë©ë‹ˆë‹¤.")


# ---------------------- 9. í•˜ë‹¨: ëˆ„ì  ëª©ë¡ + CSV ----------------------
st.divider()
st.subheader("ğŸ“ ì„ íƒ ë‹¨ì–´ ëª©ë¡ (ê¸°ë³¸í˜• ê¸°ì¤€)") 

selected = st.session_state.selected_words
word_info = st.session_state.word_info

if word_info:
    rows = []
    processed_lemmas = set()
    
    for tok in selected:
        clean_tok = tok
        lemma = lemmatize_ru(clean_tok)
        if lemma not in processed_lemmas and lemma in word_info:
            info = word_info[lemma]
            if info.get("ko_meanings") and info["ko_meanings"][0] != "JSON íŒŒì‹± ì˜¤ë¥˜":
                pos = info.get("pos", "í’ˆì‚¬") 
                
                if pos == 'ë™ì‚¬' and info.get("aspect_pair"):
                    imp = info['aspect_pair'].get('imp', lemma)
                    perf = info['aspect_pair'].get('perf', 'ì •ë³´ ì—†ìŒ')
                    base_form = f"{imp} / {perf}"
                else:
                    base_form = lemma

                short = "; ".join(info["ko_meanings"][:2])
                short = f"({pos}) {short}" 

                rows.append({"ê¸°ë³¸í˜•": base_form, "ëŒ€í‘œ ëœ»": short})
                processed_lemmas.add(lemma)

    if rows:
        df = pd.DataFrame(rows)
        st.dataframe(df, hide_index=True)
    else:
        st.info("ì„ íƒëœ ë‹¨ì–´ì˜ ì •ë³´ê°€ ë¡œë“œ ì¤‘ì´ê±°ë‚˜, í‘œì‹œí•  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")


# ---------------------- 10. í•˜ë‹¨: í•œêµ­ì–´ ë²ˆì—­ë³¸ (ê°€ì¥ ì•„ë˜ì— ìœ„ì¹˜) ----------------------
st.divider()
st.subheader("í•œêµ­ì–´ ë²ˆì—­ë³¸") 

if st.session_state.translated_text == "" or current_text != st.session_state.last_processed_text:
    st.session_state.translated_text = translate_text(
        current_text, 
        st.session_state.selected_words
    )
    st.session_state.last_processed_text = current_text

translated_text = st.session_state.translated_text

if translated_text.startswith("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€"):
    st.error(translated_text)
elif translated_text.startswith("ë²ˆì—­ ì˜¤ë¥˜ ë°œìƒ"):
    st.error(translated_text)
else:
    st.markdown(f'<div class="text-container" style="color: #333; font-weight: 500;">{translated_text}</div>', unsafe_allow_html=True)

# ---------------------- 11. ì €ì‘ê¶Œ í‘œì‹œ (í˜ì´ì§€ ìµœí•˜ë‹¨) ----------------------
st.markdown("---")
st.markdown("""
<div style="text-align: center; font-size: 0.75em; color: #888;">
    ì´ í˜ì´ì§€ëŠ” ì—°ì„¸ëŒ€í•™êµ ë…¸ì–´ë…¸ë¬¸í•™ê³¼ 25-2 ëŸ¬ì‹œì•„ì–´ êµìœ¡ë¡  5íŒ€ì˜ í”„ë¡œì íŠ¸ ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤. 
    <br>
    ë³¸ í˜ì´ì§€ì˜ ë‚´ìš©, ê¸°ëŠ¥ ë° ë°ì´í„°ë¥¼ í•™ìŠµ ëª©ì  ì´ì™¸ì˜ ìš©ë„ë¡œ ë¬´ë‹¨ ë³µì œ, ë°°í¬, ìƒì—…ì  ì´ìš©í•  ê²½ìš°, 
    ê´€ë ¨ ë²•ë ¹ì— ë”°ë¼ ë¯¼ì‚¬ìƒ ì†í•´ë°°ìƒ ì²­êµ¬ ë° í˜•ì‚¬ìƒ ì²˜ë²Œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
</div>
""", unsafe_allow_html=True)
