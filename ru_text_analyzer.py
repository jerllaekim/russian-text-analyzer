import streamlit as st
import re
import os
import json
import pandas as pd
from pymystem3 import Mystem
from google import genai

# ---------------------- 0. ì´ˆê¸° ì„¤ì • ë° ì„¸ì…˜ ìƒíƒœ ----------------------
st.set_page_config(page_title="ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ‡·ğŸ‡º ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "selected_words" not in st.session_state:
    st.session_state.selected_words = []
if "clicked_word" not in st.session_state:
    st.session_state.clicked_word = None
if "word_info" not in st.session_state:
    st.session_state.word_info = {}
if "manual_search_word" not in st.session_state:
    st.session_state.manual_search_word = ""

mystem = Mystem()

@st.cache_data(show_spinner=False)
def lemmatize_ru(word: str) -> str:
    """ë‹¨ì–´ì˜ ê¸°ë³¸í˜•(lemma)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        lemmas = mystem.lemmatize(word)
        return (lemmas[0] if lemmas else word).strip()
    return word

# ---------------------- 1. Gemini ì—°ë™ í•¨ìˆ˜ ----------------------

api_key = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY"))
client = genai.Client(api_key=api_key) if api_key else None

SYSTEM_PROMPT = "ë„ˆëŠ” ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ í•™ìŠµì„ ë•ëŠ” ë„ìš°ë¯¸ì´ë‹¤. ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´ì— ëŒ€í•´ ê°„ë‹¨í•œ í•œêµ­ì–´ ëœ»ê³¼ ì˜ˆë¬¸ì„ ìµœëŒ€ ë‘ ê°œë§Œ ì œê³µí•œë‹¤. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤."
def make_prompt(word, lemma):
    return f"""{SYSTEM_PROMPT}
ë‹¨ì–´: {word}
ê¸°ë³¸í˜•: {lemma}
{{ "ko_meanings": ["ëœ»1", "ëœ»2"], "examples": [ {{"ru": "ì˜ˆë¬¸1", "ko": "ë²ˆì—­1"}}, {{"ru": "ì˜ˆë¬¸2", "ko": "ë²ˆì—­2"}} ] }}
"""

@st.cache_data(show_spinner=False)
def fetch_from_gemini(word, lemma):
    if not client:
        return {"ko_meanings": [f"'{word}'ì˜ API í‚¤ ì—†ìŒ (GEMINI_API_KEY ì„¤ì • í•„ìš”)"], "examples": []}
        
    prompt = make_prompt(word, lemma)
    res = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
    text = res.text.strip()
    
    # --- [JSON íŒŒì‹± ë¡œì§ ê°•í™”] ---
    try:
        # 1. Markdown ì½”ë“œ ë¸”ë¡ ì œê±°
        if text.startswith("```"):
            text = text.strip("`")
            lines = text.splitlines()
            if lines and lines[0].lower().startswith("json"):
                text = "\n".join(lines[1:])
            elif lines:
                 text = "\n".join(lines)
                 
        # 2. JSON ë¬¸ìì—´ì˜ ì‹œì‘(ì²« '{')ê³¼ ë(ë§ˆì§€ë§‰ '}') ì¸ë±ìŠ¤ ì°¾ê¸°
        start_index = text.find('{')
        end_index = text.rfind('}')
        
        if start_index != -1 and end_index != -1 and end_index > start_index:
            json_text = text[start_index : end_index + 1]
        else:
            json_text = text
            
        data = json.loads(json_text)
        
        # 3. ì˜ˆë¬¸ ê°œìˆ˜ ì œí•œ ë¡œì§
        if 'examples' in data and len(data['examples']) > 2:
            data['examples'] = data['examples'][:2]
        return data
    
    except json.JSONDecodeError:
        st.error(f"Gemini ì‘ë‹µì„ JSONìœ¼ë¡œ ë””ì½”ë”©í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸ ì‹œì‘: {text[:100]}...")
        return {"ko_meanings": ["JSON íŒŒì‹± ì˜¤ë¥˜"], "examples": []}

# ---------------------- 2. ì „ì—­ ìŠ¤íƒ€ì¼ ë° JavaScript ì •ì˜ ----------------------

# JavaScript: ë‹¨ì–´ í´ë¦­ ì‹œ ê²€ìƒ‰ì°½ì— í…ìŠ¤íŠ¸ë¥¼ ì±„ìš°ê³ , ì´ë²¤íŠ¸(input)ë¥¼ ë°œìƒì‹œì¼œ Streamlitì˜ ì¬ì‹¤í–‰ì„ ìœ ë„í•©ë‹ˆë‹¤.
# ì´ í•¨ìˆ˜ê°€ 'ìë™ ê²€ìƒ‰'ì„ êµ¬í˜„í•˜ëŠ” í•µì‹¬ì´ì§€ë§Œ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
st.markdown("""
<script>
    function setManualSearchWordAndRerun(word) {
        // 1. 'ë‹¨ì–´ ì§ì ‘ ì…ë ¥' í•„ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤. (ARIA-LABEL ê¸°ë°˜)
        const inputField = document.querySelector('[aria-label="ë‹¨ì–´ ì§ì ‘ ì…ë ¥"]');
        if (inputField) {
            // 2. ê°’ì„ ì„¤ì •í•©ë‹ˆë‹¤.
            inputField.value = word;
            
            // 3. 'input' ì´ë²¤íŠ¸ë¥¼ ê°•ì œ ë°œìƒì‹œì¼œ Streamlitì—ê²Œ ê°’ì´ ë³€ê²½ë˜ì—ˆìŒì„ ì•Œë¦½ë‹ˆë‹¤.
            //    ì´ê²ƒì´ Python ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  í˜ì´ì§€ë¥¼ ì¬ì‹¤í–‰(RERUN)í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
            const event = new Event('input', { bubbles: true });
            inputField.dispatchEvent(event);
        } else {
             // 4. Input í•„ë“œë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ë³µì‚¬ë§Œ í•©ë‹ˆë‹¤.
             navigator.clipboard.writeText(word);
             alert(`ì£„ì†¡í•©ë‹ˆë‹¤. ìë™ ê²€ìƒ‰ì´ ì‘ë™í•˜ì§€ ì•Šì•„ '${word}'ë¥¼ í´ë¦½ë³´ë“œì— ë³µì‚¬í–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ì°½ì— ë¶™ì—¬ë„£ì–´ ì£¼ì„¸ìš”.`);
        }
    }
</script>
""", unsafe_allow_html=True)

st.markdown("""
<style>
    /* (CSS ìŠ¤íƒ€ì¼ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ë˜ì–´ íŒŒë€ìƒ‰ ê¸€ì”¨ì™€ êµ¬ë‘ì  ë°°ì¹˜ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.) */
    .word-span {
        cursor: pointer;
        padding: 0px 0px;
        margin: 0px 0px;
        display: inline-block;
        transition: color 0.2s;
        user-select: none;
        white-space: pre; 
        font-size: 1.25em;
    }
    .word-span:hover {
        color: #007bff;
        text-decoration: underline;
    }
    
    .word-selected {
        color: #007bff !important; 
        font-weight: bold;
    }
    
    .word-punctuation {
        padding: 0px 0px;
        margin: 0;
        display: inline-block;
        user-select: none;
        white-space: pre;
        font-size: 1.25em;
    }
    
    .text-container {
        line-height: 2.0;
        margin-bottom: 20px;
    }
</style>
""", unsafe_allow_html=True)


# ---------------------- 3. ì§ì ‘ ë‹¨ì–´ ê²€ìƒ‰ (ìƒë‹¨) ë° ì²˜ë¦¬ ë¡œì§ ----------------------
st.divider()
st.subheader("ğŸ” ì§ì ‘ ë‹¨ì–´ ê²€ìƒ‰")

# ê²€ìƒ‰ ì…ë ¥ í•„ë“œ (key="manual_search_word"ë¡œ ì„¸ì…˜ ìƒíƒœì— ë°”ì¸ë”©)
manual_input = st.text_input("ë‹¨ì–´ ì§ì ‘ ì…ë ¥", key="manual_search_word")

# ê²€ìƒ‰ ì…ë ¥ ì²˜ë¦¬ ë¡œì§
if manual_input:
    # 1. ê²€ìƒ‰ëœ ë‹¨ì–´ë¥¼ ì„ íƒ ëª©ë¡ì— ì¶”ê°€ (íŒŒë€ìƒ‰ ê¸€ì”¨ ìœ ì§€ë¥¼ ìœ„í•¨)
    if manual_input not in st.session_state.selected_words:
        st.session_state.selected_words.append(manual_input)
    
    # 2. ìƒì„¸ ì •ë³´ ì˜ì—­ì— í‘œì‹œë  ë‹¨ì–´ ì—…ë°ì´íŠ¸
    st.session_state.clicked_word = manual_input
    
    # ************** ê²€ìƒ‰ ìƒì„¸ ì •ë³´ í‘œì‹œ **************
    lemma = lemmatize_ru(manual_input)
    st.markdown(f"**ì…ë ¥ ë‹¨ì–´:** **{manual_input}**")
    st.markdown(f"**ê¸°ë³¸í˜•(lemma):** *{lemma}*")

    try:
        info = fetch_from_gemini(manual_input, lemma)
        
        # *** FIX for Issue 1: ê²€ìƒ‰ëœ ë‹¨ì–´ì˜ ì •ë³´ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ì—¬ í•˜ë‹¨ ëª©ë¡ì— ì¶”ê°€ë˜ë„ë¡ í•¨ ***
        if lemma not in st.session_state.word_info or st.session_state.word_info.get(lemma, {}).get('loaded_token') != manual_input:
             st.session_state.word_info[lemma] = {**info, "loaded_token": manual_input} 
        
    except Exception as e:
        st.error(f"Gemini ì˜¤ë¥˜: {e}")
        info = {}

    ko_meanings = info.get("ko_meanings", [])
    examples = info.get("examples", [])

    if ko_meanings:
        st.markdown("#### í•œêµ­ì–´ ëœ»")
        for m in ko_meanings:
            st.markdown(f"- **{m}**")

    if examples:
        st.markdown("#### ğŸ“– ì˜ˆë¬¸")
        for ex in examples:
            st.markdown(f"- **{ex.get('ru','')}**")
            st.markdown(f"â€ƒâ†’ {ex.get('ko','')}")
    
    st.markdown("---")


# ---------------------- 4. ë©”ì¸ í…ìŠ¤íŠ¸ ë° ë ˆì´ì•„ì›ƒ ----------------------

text = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", "Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ ÑƒĞ»Ğ¸Ñ†Ğµ. Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°. Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾.", height=150)
tokens_with_punct = re.findall(r"(\w+|[^\s\w]+|\s+)", text, flags=re.UNICODE)

left, right = st.columns([2, 1])

# --- 4.1. ë‹¨ì–´ ëª©ë¡ ë° í´ë¦­ ì²˜ë¦¬ (left ì»¬ëŸ¼) ---
with left:
    st.subheader("ë‹¨ì–´ ëª©ë¡ (í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ)")

    html_all = ['<div class="text-container">']
    
    for tok in tokens_with_punct:
        if re.fullmatch(r'\w+', tok, flags=re.UNICODE):
            is_selected = tok in st.session_state.selected_words
            css = "word-span"
            
            # íŒŒë€ìƒ‰ ê¸€ì”¨ ìœ ì§€: ì„ íƒëœ ë‹¨ì–´ì— í´ë˜ìŠ¤ë¥¼ ì§ì ‘ ì‚½ì…
            if is_selected:
                css += " word-selected"
            
            # onclick: JavaScript í•¨ìˆ˜ í˜¸ì¶œ (í´ë¦­ ì‹œ ìë™ ê²€ìƒ‰ ì‹œë„)
            html_all.append(
                f'<span class="{css}" onclick="setManualSearchWordAndRerun(\'{tok}\');">'
                f'{tok}'
                f'</span>'
            )

        else:
            # êµ¬ë‘ì  ë˜ëŠ” ê³µë°±
            html_all.append(f'<span class="word-punctuation">{tok}</span>')

    html_all.append('</div>')
    
    st.markdown("".join(html_all), unsafe_allow_html=True)
    
    # ì´ˆê¸°í™” ë²„íŠ¼
    st.markdown("---")
    if st.button("ğŸ”„ ì„ íƒ ë° ê²€ìƒ‰ ì´ˆê¸°í™”", key="reset_button"):
        st.session_state.selected_words = []
        st.session_state.clicked_word = None
        st.session_state.word_info = {}
        st.session_state.manual_search_word = ""
        st.rerun()

# --- 4.2. ë‹¨ì–´ ìƒì„¸ ì •ë³´ (right ì»¬ëŸ¼) ---
with right:
    st.subheader("ë‹¨ì–´ ìƒì„¸ ì •ë³´")
    
    current_token = st.session_state.clicked_word
    
    if current_token:
        lemma = lemmatize_ru(current_token)
        info = st.session_state.word_info.get(lemma, {})

        if info and "ko_meanings" in info:
            st.markdown(f"### **{current_token}**")
            st.markdown(f"**ê¸°ë³¸í˜• (Lemma):** *{lemma}*")
            st.divider()

            ko_meanings = info.get("ko_meanings", [])
            examples = info.get("examples", [])

            if ko_meanings:
                st.markdown("#### í•œêµ­ì–´ ëœ»")
                for m in ko_meanings:
                    st.markdown(f"- **{m}**")

            if examples:
                st.markdown("#### ğŸ“– ì˜ˆë¬¸")
                for ex in examples:
                    st.markdown(f"- {ex.get('ru', '')}")
                    st.markdown(f"â€ƒâ†’ {ex.get('ko', '')}")
            else:
                if ko_meanings and ko_meanings[0].startswith("JSON íŒŒì‹± ì˜¤ë¥˜"):
                     st.error("Gemini APIì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ í˜•ì‹ì´ ë°˜í™˜ë˜ì–´ ì •ë³´ í‘œì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                elif ko_meanings and ko_meanings[0].startswith(f"'{current_token}'ì˜ API í‚¤ ì—†ìŒ"):
                     st.warning("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì˜ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ì˜ˆë¬¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ë‹¨ì–´ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì´ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            
    else:
        st.info("ì™¼ìª½ í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ë¥¼ í´ë¦­í•˜ì—¬ ìë™ ê²€ìƒ‰ì„ ì‹œë„í•˜ê±°ë‚˜, ìœ„ ê²€ìƒ‰ì°½ì„ ì´ìš©í•´ì£¼ì„¸ìš”.")

# ---------------------- 5. í•˜ë‹¨: ëˆ„ì  ëª©ë¡ + CSV ----------------------
st.divider()
st.subheader("ğŸ“ ì„ íƒí•œ ë‹¨ì–´ ëª¨ìŒ (ê¸°ë³¸í˜• ê¸°ì¤€)")

selected = st.session_state.selected_words
word_info = st.session_state.word_info

if word_info:
    rows = []
    processed_lemmas = set()
    
    # ì„ íƒëœ ë‹¨ì–´ ëª©ë¡ì„ ìˆœíšŒí•˜ë©°, í•´ë‹¹ ë‹¨ì–´ì˜ ê¸°ë³¸í˜• ì •ë³´ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    for tok in selected:
        lemma = lemmatize_ru(tok)
        if lemma not in processed_lemmas and lemma in word_info:
            info = word_info[lemma]
            # JSON íŒŒì‹± ì˜¤ë¥˜ ë‹¨ì–´ëŠ” ì œì™¸
            if info.get("ko_meanings") and info["ko_meanings"][0] != "JSON íŒŒì‹± ì˜¤ë¥˜":
                short = "; ".join(info["ko_meanings"][:2])
                rows.append({"ê¸°ë³¸í˜•": lemma, "ëŒ€í‘œ ëœ»": short})
                processed_lemmas.add(lemma)

    if rows:
        df = pd.DataFrame(rows)
        st.dataframe(df, hide_index=True)

        csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ’¾ CSVë¡œ ì €ì¥", csv_bytes, "russian_words.csv", "text/csv")
    else:
        st.info("ì„ íƒëœ ë‹¨ì–´ì˜ ì •ë³´ê°€ ë¡œë“œ ì¤‘ì´ê±°ë‚˜, í‘œì‹œí•  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
