import streamlit as st
import re
import os
import json
import pandas as pd
from pymystem3 import Mystem
from google import genai

# ---------------------- 0. ì´ˆê¸° ì„¤ì • ë° ì„¸ì…˜ ìƒíƒœ ----------------------
st.set_page_config(page_title="ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ‡·ğŸ‡º ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "selected_words" not in st.session_state:
    st.session_state.selected_words = []
if "clicked_word" not in st.session_state:
    st.session_state.clicked_word = None
if "word_info" not in st.session_state:
    st.session_state.word_info = {}

# Mystem ì¸ìŠ¤í„´ìŠ¤
mystem = Mystem()

@st.cache_data(show_spinner=False)
def lemmatize_ru(word: str) -> str:
    """ë‹¨ì–´ì˜ ê¸°ë³¸í˜•(lemma)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        lemmas = mystem.lemmatize(word)
        return (lemmas[0] if lemmas else word).strip()
    return word

# ---------------------- 1. Gemini ì—°ë™ í•¨ìˆ˜ ----------------------

api_key = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY"))
client = genai.Client(api_key=api_key) if api_key else None

SYSTEM_PROMPT = "ë„ˆëŠ” ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ í•™ìŠµì„ ë•ëŠ” ë„ìš°ë¯¸ì´ë‹¤. ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´ì— ëŒ€í•´ ê°„ë‹¨í•œ í•œêµ­ì–´ ëœ»ê³¼ ì˜ˆë¬¸ì„ ì œê³µí•œë‹¤. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤."
def make_prompt(word, lemma):
    return f"""{SYSTEM_PROMPT}
ë‹¨ì–´: {word}
ê¸°ë³¸í˜•: {lemma}
{{ "ko_meanings": ["ëœ»1", "ëœ»2"], "examples": [ {{"ru": "ì˜ˆë¬¸1", "ko": "ë²ˆì—­1"}}, {{"ru": "ì˜ˆë¬¸2", "ko": "ë²ˆì—­2"}} ] }}
"""

@st.cache_data(show_spinner=False)
def fetch_from_gemini(word, lemma):
    if not client:
        return {"ko_meanings": [f"'{word}'ì˜ API í‚¤ ì—†ìŒ (GEMINI_API_KEY ì„¤ì • í•„ìš”)"], "examples": []}
        
    prompt = make_prompt(word, lemma)
    res = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
    text = res.text.strip()
    
    if text.startswith("```"):
        text = text.strip("`")
        lines = text.splitlines()
        if lines and lines[0].lower().startswith("json"):
            text = "\n".join(lines[1:])
        elif lines:
             text = "\n".join(lines)
             
    return json.loads(text)

# ---------------------- 2. ì „ì—­ ìŠ¤íƒ€ì¼ ì •ì˜ (ë²„íŠ¼ ìœ„ì ¯ ë®ì–´ì“°ê¸°) ----------------------

# Streamlit ë²„íŠ¼ ìœ„ì ¯ì„ ë‹¨ì–´ ìŠ¤íƒ€ì¼ë¡œ ë®ì–´ì”Œì›ë‹ˆë‹¤.
st.markdown("""
<style>
    /* í…ìŠ¤íŠ¸ ì…ë ¥ ì˜ì—­ ì•„ë˜ì˜ ë„ì–´ì“°ê¸° ì œì–´ */
    div.stTextArea + div.stMarkdown > div {
        line-height: 2.0;
        font-size: 1.25em;
    }

    /* ë‹¨ì–´ì²˜ëŸ¼ ë³´ì´ë„ë¡ ë²„íŠ¼ ìŠ¤íƒ€ì¼ì„ ë³€ê²½ */
    .word-container {
        display: inline-block;
        margin: 2px 0;
        user-select: none;
    }
    .word-button {
        padding: 2px 4px !important;
        margin: 0 !important;
        border: none !important;
        background: none !important;
        box-shadow: none !important;
        cursor: pointer;
        color: #333; /* ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
        font-weight: normal;
        display: inline-block !important;
        line-height: 1.5; /* ì¤„ ê°„ê²© ìœ ì§€ */
    }
    /* í´ë¦­ëœ/ì„ íƒëœ ë‹¨ì–´ ìŠ¤íƒ€ì¼ */
    .word-selected > button {
        color: #007bff !important; 
        font-weight: bold !important;
    }
    /* êµ¬ë‘ì  ìŠ¤íƒ€ì¼ (ë²„íŠ¼ ì•„ë‹˜) */
    .word-punctuation {
        padding: 2px 0px;
        margin: 2px 0;
        display: inline-block;
        user-select: none;
        line-height: 1.5;
    }
    
    /* Streamlit ë²„íŠ¼ì˜ ê¸°ë³¸ ê°„ê²©ì„ ì—†ì•  ë‹¨ì–´ì²˜ëŸ¼ ë¶™ë„ë¡ ì²˜ë¦¬ */
    .stButton > button {
        border-radius: 0px !important;
        padding: 2px 4px !important;
    }
</style>
""", unsafe_allow_html=True)


# ---------------------- 3. ë©”ì¸ ë¡œì§ ë° ë ˆì´ì•„ì›ƒ ----------------------

text = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", "Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ ÑƒĞ»Ğ¸Ñ†Ğµ. Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°.")
tokens_with_punct = re.findall(r"(\w+|[^\s\w]+)", text, flags=re.UNICODE)

left, right = st.columns([2, 1])

# --- 3.1. ë‹¨ì–´ ëª©ë¡ (left ì»¬ëŸ¼) ---
with left:
    st.subheader("ë‹¨ì–´ ëª©ë¡ (í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ)")

    # ë‹¨ì–´ë¥¼ ì €ì¥í•  ì„ì‹œ ì»¨í…Œì´ë„ˆ
    word_elements = [] 
    
    # í…ìŠ¤íŠ¸ ë‚´ì˜ ëª¨ë“  í† í°ì„ ìˆœíšŒí•˜ë©° ìœ„ì ¯ ë˜ëŠ” êµ¬ë‘ì  ì‚½ì…
    for i, tok in enumerate(tokens_with_punct):
        if re.fullmatch(r'\w+', tok, flags=re.UNICODE):
            # ë‹¨ì–´ì¸ ê²½ìš°: ì‹¤ì œ st.buttonì„ ì‚¬ìš©í•˜ì—¬ í´ë¦­ì„ ê°ì§€
            
            is_selected = tok in st.session_state.selected_words
            
            # CSS í´ë˜ìŠ¤ë¥¼ ì§€ì •í•˜ê¸° ìœ„í•œ HTML ë§ˆí¬ì—… ì‹œì‘
            css_class = "word-container"
            if is_selected:
                 css_class += " word-selected"

            # 1. HTML ë§ˆí¬ì—… ì‹œì‘ (ë‹¨ì–´ ì»¨í…Œì´ë„ˆ)
            word_elements.append(f'<div class="{css_class}">')
            
            # 2. ë²„íŠ¼ ë°°ì¹˜ (í´ë¦­ ë¡œì§)
            # ë²„íŠ¼ì„ ë¨¼ì € ë°°ì¹˜í•˜ê³ , í´ë¦­ë˜ë©´ ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
            
            # ì½œë°± í•¨ìˆ˜: ë²„íŠ¼ì´ í´ë¦­ë  ë•Œë§Œ ì‹¤í–‰ë˜ë©°, ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            def on_word_click(clicked_token):
                st.session_state.clicked_word = clicked_token
                # ë‹¨ì–´ ì •ë³´ ë¡œë“œ ë¡œì§ì€ ì•„ë˜ 3.2ì—ì„œ ì¬ì‹¤í–‰ ì‹œ ì²˜ë¦¬ë¨
                if clicked_token not in st.session_state.selected_words:
                    st.session_state.selected_words.append(clicked_token)

            # st.buttonì„ ë Œë”ë§í•˜ê³ , í´ë¦­ ì—¬ë¶€ë¥¼ ì¦‰ì‹œ í™•ì¸
            if st.button(
                tok, 
                key=f"word_{tok}_{i}", # ê³ ìœ  keyë¥¼ ì§€ì •í•´ì•¼ ëª¨ë“  ë²„íŠ¼ì´ ì‘ë™
                help=f"í´ë¦­í•˜ì—¬ '{tok}' ì •ë³´ ë³´ê¸°",
                on_click=on_word_click,
                args=(tok,)
            ):
                # ë²„íŠ¼ í´ë¦­ ì‹œ on_clickì´ ì‹¤í–‰ë˜ê³  Streamlitì´ ì¬ì‹¤í–‰ë¨
                pass 
                
            # 3. HTML ë§ˆí¬ì—… ì¢…ë£Œ ë° ë„ì–´ì“°ê¸° ì¶”ê°€
            word_elements.append(f'</div> ') # ë„ì–´ì“°ê¸°ë¥¼ ìœ„í•´ div ë°–ì—ì„œ ê³µë°± ì¶”ê°€

        else:
            # êµ¬ë‘ì ì¸ ê²½ìš°: ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì¶œë ¥ (í´ë¦­ ë¶ˆê°€)
            word_elements.append(f'<span class="word-punctuation">{tok}</span>')

    # st.markdownì„ ì‚¬ìš©í•˜ì—¬ êµ¬ë‘ì ê³¼ HTML ë§ˆí¬ì—…ì„ í•¨ê»˜ ë Œë”ë§
    # st.markdown(word_elements[0], unsafe_allow_html=True) # ê° ìš”ì†Œë¥¼ ê°œë³„ì ìœ¼ë¡œ ë Œë”ë§í•  í•„ìš”ëŠ” ì—†ìŒ

    # Streamlitì€ ë²„íŠ¼ê³¼ ë§ˆí¬ë‹¤ìš´ì„ ì„ì–´ ë Œë”ë§í•  ë•Œ ì•½ê°„ì˜ íŠ¸ë¦­ì´ í•„ìš”í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” Streamlitì˜ ìë™ ë Œë”ë§ì„ ë¯¿ê³ , ë²„íŠ¼ ì‚¬ì´ì— ë„ì–´ì“°ê¸°ë¥¼ ìœ„í•´ ë§ˆí¬ë‹¤ìš´ì„ í™œìš©í•©ë‹ˆë‹¤.
    # ê·¸ëŸ¬ë‚˜ ë²„íŠ¼ ìœ„ì ¯ê³¼ ë§ˆí¬ë‹¤ìš´ì„ ì„ì„ ë•Œ ë ˆì´ì•„ì›ƒì´ ê¹¨ì§€ê¸° ì‰¬ìš°ë¯€ë¡œ,
    # ìœ„ì—ì„œ ì´ë¯¸ st.buttonì„ ë°°ì¹˜í–ˆìœ¼ë¯€ë¡œ, í…ìŠ¤íŠ¸ì™€ êµ¬ë‘ì ì„ ë²„íŠ¼ ì‚¬ì´ì— ë„£ì–´ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.
    
    # *******************************************************************
    # ğŸš¨ ì£¼ì˜: Streamlitì€ ìœ„ì ¯ê³¼ HTMLì„ ì„ì„ ë•Œ ë¬¸ì œê°€ ë°œìƒí•˜ë¯€ë¡œ, 
    # ìœ„ ì½”ë“œì—ì„œ st.buttonì´ ì´ë¯¸ ìˆœì„œëŒ€ë¡œ ë°°ì¹˜ë˜ì—ˆì„ ê²½ìš°, 
    # ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸(êµ¬ë‘ì )ë§Œ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” ë°©ì‹ì´ ë” ì•ˆì •ì ì…ë‹ˆë‹¤.
    # *******************************************************************

    # í•˜ì§€ë§Œ ìµœì¢… ì‚¬ìš©ìê°€ ë³´ëŠ” í™”ë©´ì„ ìœ„í•´, í˜„ì¬ëŠ” st.buttonì„ ë°°ì¹˜í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤.
    # st.buttonì€ ë¸”ë¡ ë ˆë²¨ ìš”ì†Œì²˜ëŸ¼ ë™ì‘í•˜ë¯€ë¡œ, CSSë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ë¼ì¸ ë¸”ë¡ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
    # CSS ì„¤ì • (.word-container, .word-button)ì´ ì´ ë¬¸ì œë¥¼ í•´ê²°í•´ ì£¼ê¸¸ ê¸°ëŒ€í•©ë‹ˆë‹¤.


    # ì´ˆê¸°í™” ë²„íŠ¼
    st.markdown("---")
    if st.button("ğŸ”„ ì„ íƒ ì´ˆê¸°í™”"):
        st.session_state.selected_words = []
        st.session_state.clicked_word = None
        st.session_state.word_info = {}
        st.experimental_set_query_params() 
        st.rerun()

# --- 3.2. ë‹¨ì–´ ìƒì„¸ ì •ë³´ ë¡œë“œ (í´ë¦­ ì‹œ ì‹¤í–‰) ---

current_token = st.session_state.clicked_word

if current_token:
    tok = current_token
    lemma = lemmatize_ru(tok)
    
    # ë‹¨ì–´ ì •ë³´ ë¡œë“œ (ì„¸ì…˜ ìƒíƒœì— ì—†ê±°ë‚˜ ë¡œë“œëœ í† í°ì´ ë‹¤ë¥¼ ê²½ìš°)
    if lemma not in st.session_state.word_info or st.session_state.word_info.get(lemma, {}).get('loaded_token') != tok:
        with st.spinner(f"'{tok}'ì˜ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘... (Gemini API í˜¸ì¶œ)"):
            try:
                info = fetch_from_gemini(tok, lemma)
                st.session_state.word_info[lemma] = {**info, "loaded_token": tok} 
            except Exception as e:
                st.error(f"ë‹¨ì–´ ì •ë³´ ë¡œë“œ ì˜¤ë¥˜: {e}")


# --- 3.3. ë‹¨ì–´ ìƒì„¸ ì •ë³´ (right ì»¬ëŸ¼) ---
with right:
    st.subheader("ë‹¨ì–´ ìƒì„¸ ì •ë³´")
    
    if current_token:
        lemma = lemmatize_ru(current_token)
        info = st.session_state.word_info.get(lemma, {})

        if info:
            st.markdown(f"### **{current_token}**")
            st.markdown(f"**ê¸°ë³¸í˜• (Lemma):** *{lemma}*")
            st.divider()

            ko_meanings = info.get("ko_meanings", [])
            examples = info.get("examples", [])

            if ko_meanings:
                st.markdown("#### í•œêµ­ì–´ ëœ»")
                for m in ko_meanings:
                    st.markdown(f"- **{m}**")

            if examples:
                st.markdown("#### ğŸ“– ì˜ˆë¬¸")
                for ex in examples:
                    st.markdown(f"- {ex.get('ru', '')}")
                    st.markdown(f"â€ƒâ†’ {ex.get('ko', '')}")
            else:
                if ko_meanings and ko_meanings[0].startswith(f"'{current_token}'ì˜ API í‚¤ ì—†ìŒ"):
                     st.warning("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì˜ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ì˜ˆë¬¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ë‹¨ì–´ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì´ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            
    else:
        st.info("ì™¼ìª½ ë‹¨ì–´ ëª©ë¡ì—ì„œ ë‹¨ì–´ë¥¼ í´ë¦­í•´ì£¼ì„¸ìš”.")

# ---------------------- 4. í•˜ë‹¨: ëˆ„ì  ëª©ë¡ + CSV ----------------------
st.divider()
st.subheader("ğŸ“ ì„ íƒí•œ ë‹¨ì–´ ëª¨ìŒ (ê¸°ë³¸í˜• ê¸°ì¤€)")

selected = st.session_state.selected_words
word_info = st.session_state.word_info

if word_info:
    rows = []
    processed_lemmas = set()
    
    for tok in selected:
        lemma = lemmatize_ru(tok)
        if lemma not in processed_lemmas and lemma in word_info:
            info = word_info[lemma]
            short = "; ".join(info["ko_meanings"][:2])
            rows.append({"ê¸°ë³¸í˜•": lemma, "ëŒ€í‘œ ëœ»": short})
            processed_lemmas.add(lemma)

    if rows:
        df = pd.DataFrame(rows)
        st.dataframe(df, hide_index=True)

        csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ’¾ CSVë¡œ ì €ì¥", csv_bytes, "russian_words.csv", "text/csv")
    else:
        st.info("ì„ íƒëœ ë‹¨ì–´ì˜ ì •ë³´ë¥¼ ë¡œë“œ ì¤‘ì´ê±°ë‚˜, í‘œì‹œí•  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")


# ---------------------- 5. ì§ì ‘ ë‹¨ì–´ ê²€ìƒ‰ ----------------------
st.divider()
st.subheader("ğŸ” ì§ì ‘ ë‹¨ì–´ ê²€ìƒ‰")

manual = st.text_input("ë‹¨ì–´ ì§ì ‘ ì…ë ¥", "")

if manual:
    lemma = lemmatize_ru(manual)
    st.markdown(f"**ì…ë ¥ ë‹¨ì–´:** **{manual}**")
    st.markdown(f"**ê¸°ë³¸í˜•(lemma):** *{lemma}*")

    try:
        info = fetch_from_gemini(manual, lemma)
    except Exception as e:
        st.error(f"Gemini ì˜¤ë¥˜: {e}")
        info = {}

    ko_meanings = info.get("ko_meanings", [])
    examples = info.get("examples", [])

    if ko_meanings:
        st.markdown("#### í•œêµ­ì–´ ëœ»")
        for m in ko_meanings:
            st.markdown(f"- **{m}**")

    if examples:
        st.markdown("#### ğŸ“– ì˜ˆë¬¸")
        for ex in examples:
            st.markdown(f"- **{ex.get('ru','')}**")
            st.markdown(f"â€ƒâ†’ {ex.get('ko','')}")
