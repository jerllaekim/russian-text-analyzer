import streamlit as st
import re
import os
import json
import pandas as pd
from pymystem3 import Mystem
from google import genai
import urllib.parse
from typing import Union

# ---------------------- 0. ì´ˆê¸° ì„¤ì • ë° ìƒìˆ˜ ----------------------

NEW_DEFAULT_TEXT = """Ğ¢Ğ¾Ğ¼ Ğ¶Ğ¸Ğ²Ñ‘Ñ‚ Ğ² Ğ¡Ğ°Ğ½ĞºÑ‚-ĞŸĞµÑ‚ĞµÑ€Ğ±ÑƒÑ€Ğ³Ğµ ÑƒĞ¶Ğµ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼ĞµÑÑÑ†ĞµĞ². Ğ’ ÑÑƒĞ±Ğ±Ğ¾Ñ‚Ñƒ, ĞºĞ¾Ğ³Ğ´Ğ° Ğ±Ñ‹Ğ»Ğ° Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ°, Ğ¢Ğ¾Ğ¼ Ñ€ĞµÑˆĞ¸Ğ» Ğ¿Ğ¾Ğ¹Ñ‚Ğ¸ Ğ² Ğ˜ÑĞ°Ğ°ĞºĞ¸ĞµĞ²ÑĞºĞ¸Ğ¹ ÑĞ¾Ğ±Ğ¾Ñ€. Ğ¢Ğ¾Ğ¼ Ğ´Ğ°Ğ²Ğ½Ğ¾ Ğ¼ĞµÑ‡Ñ‚Ğ°Ğ» Ğ¿Ğ¾Ğ±Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ² ÑÑ‚Ğ¾Ğ¼ ÑĞ¾Ğ±Ğ¾Ñ€Ğµ. Ğ˜ì‚¬ì•„í‚¤ì˜ˆí”„ìŠ¤í‚¤ ì†Œë³´ë¥´ â€” Ğ¾Ğ´Ğ½Ğ¾ Ğ¸Ğ· ÑĞ°Ğ¼Ñ‹Ñ… Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ñ… Ğ·Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ğ² Ğ¡Ğ°Ğ½ĞºÑ‚-ĞŸĞµÑ‚ĞµÑ€Ğ±ÑƒÑ€Ğ³Ğµ, ĞµĞ³Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑƒĞ²Ğ¸Ğ´ĞµÑ‚ÑŒ Ğ´Ğ°Ğ¶Ğµ Ğ¸Ğ·Ğ´Ğ°Ğ»ĞµĞºĞ°. ĞšĞ¾Ğ³Ğ´Ğ° Ğ¢Ğ¾Ğ¼ Ğ³ÑƒĞ»ÑĞ» Ğ¿Ğ¾ Ñ†ĞµĞ½Ñ‚Ñ€Ñƒ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°, Ğ¾Ğ½ Ğ¾Ñ‚Ğ¾Ğ²ÑÑĞ´Ñƒ Ğ²Ğ¸Ğ´ĞµĞ» Ğ·Ğ¾Ğ»Ğ¾Ñ‚Ğ¾Ğ¹ ĞºÑƒĞ¿Ğ¾Ğ» ÑĞ¾Ğ±Ğ¾Ñ€Ğ°. Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¢Ğ¾Ğ¼ Ñ€ĞµÑˆĞ¸Ğ» Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ ÑĞ¾Ğ±Ğ¾Ñ€ ÑĞ½Ğ°Ñ€ÑƒĞ¶Ğ¸. ĞĞ½ Ğ¿Ñ€Ğ¸ÑˆÑ‘Ğ» Ğ½Ğ° Ğ˜ÑĞ°Ğ°ĞºĞ¸ĞµĞ²ÑĞºÑƒÑ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ÑŒ â€” Ğ¾Ñ‚ÑÑĞ´Ğ° Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¿Ñ€ĞµĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ğ²Ğ¸Ğ´ Ğ½Ğ° ÑĞ¾Ğ±Ğ¾Ñ€. ĞŸĞ¾Ñ‚Ğ¾Ğ¼ Ğ¢Ğ¾Ğ¼ Ğ¿Ğ¾Ğ´Ğ¾ÑˆÑ‘Ğ» Ğº ÑĞ¾Ğ±Ğ¾Ñ€Ñƒ Ğ¿Ğ¾Ğ±Ğ»Ğ¸Ğ¶Ğµ, Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµĞ» ĞµĞ³Ğ¾ ÑĞ¿ĞµÑ€ĞµĞ´Ğ¸, ÑĞ·Ğ°Ğ´Ğ¸, 2 Ñ€Ğ°Ğ·Ğ° Ğ¾Ğ±Ğ¾ÑˆÑ‘Ğ» Ğ²Ğ¾ĞºÑ€ÑƒĞ³ ÑĞ¾Ğ±Ğ¾Ñ€Ğ°, Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ Ğ²Ğ¾ÑˆÑ‘Ğ» Ğ²Ğ½ÑƒÑ‚Ñ€ÑŒ. Ğ’Ğ½ÑƒÑ‚Ñ€Ğ¸ ÑĞ¾Ğ±Ğ¾Ñ€ Ğ¾Ñ‡ĞµĞ½ÑŒ ĞºÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹. Ğ¢Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ», Ñ‡Ñ‚Ğ¾ ĞºÑƒĞ¿Ğ¾Ğ» ÑĞ¾Ğ±Ğ¾Ñ€Ğ° â€” Ñ‚Ñ€ĞµÑ‚Ğ¸Ğ¹ Ğ¿Ğ¾ Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ½Ğµ Ğ² Ğ•Ğ²Ñ€Ğ¾Ğ¿Ğµ. Ğ¢Ğ¾Ğ¼ Ğ¿Ğ¾Ğ´Ğ½ÑĞ» Ğ³Ğ¾Ğ»Ğ¾Ğ²Ñƒ Ğ²Ğ²ĞµÑ€Ñ… Ğ¸ ÑƒĞ²Ğ¸Ğ´ĞµĞ», Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ´ ĞºÑƒĞ¿Ğ¾Ğ»Ğ¾Ğ¼ Â«Ğ»ĞµÑ‚Ğ°ĞµÑ‚Â» ÑĞµÑ€ĞµĞ±Ñ€ÑĞ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ»ÑƒĞ±ÑŒ. Ğ¢Ğ¾Ğ¼ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµĞ» Ğ²Ğ¾ĞºÑ€ÑƒĞ³: Ğ²Ğ¿ĞµÑ€ĞµĞ´Ğ¸, ÑĞ·Ğ°Ğ´Ğ¸, ÑĞ¿Ñ€Ğ°Ğ²Ğ°, ÑĞ»ĞµĞ²Ğ° â€” Ğ²ĞµĞ·Ğ´Ğµ Ğ±Ñ‹Ğ»Ğ¸ ĞºÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğµ Ğ¸ĞºĞ¾Ğ½Ñ‹. ĞŸĞ¾Ñ‚Ğ¾Ğ¼ Ğ¢Ğ¾Ğ¼ Ñ€ĞµÑˆĞ¸Ğ» Ğ¿Ğ¾Ğ´Ğ½ÑÑ‚ÑŒÑÑ Ğ½Ğ° ĞºĞ¾Ğ»Ğ¾Ğ½Ğ½Ğ°Ğ´Ñƒ ÑĞ¾Ğ±Ğ¾Ñ€Ğ°. Ğ’ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ´ĞµĞ½ÑŒ Ğ² ÑĞ¾Ğ±Ğ¾Ñ€Ğµ Ğ±Ñ‹Ğ»Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ÑƒÑ€Ğ¸ÑÑ‚Ğ¾Ğ²: Ğ¾Ğ´Ğ½Ğ¸ Ğ¿Ğ¾Ğ´Ğ½Ğ¸Ğ¼Ğ°Ğ»Ğ¸ÑÑŒ Ğ²Ğ²ĞµÑ€Ñ…, Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ÑĞ¿ÑƒÑĞºĞ°Ğ»Ğ¸ÑÑŒ Ğ²Ğ½Ğ¸Ğ·. Ğ¢Ğ¾Ğ¼ Ñ‚Ğ¾Ğ¶Ğµ Ğ¿Ğ¾Ğ´Ğ½ÑĞ»ÑÑ Ğ²Ğ²ĞµÑ€Ñ…. ĞÑ‚Ñ‚Ñƒë‹¤, ÑĞ²ĞµÑ€Ñ…Ñƒ, Ñ Ğ²Ñ‹ÑĞ¾Ñ‚Ñ‹ 43 (ÑĞ¾Ñ€Ğ¾ĞºĞ° Ñ‚Ñ€Ñ‘Ñ…) Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¿Ñ€ĞµĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ğ²Ğ¸Ğ´ Ğ½Ğ° Ñ†ĞµĞ½Ñ‚Ñ€ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°. Ğ¢Ğ¾Ğ¼ ÑƒĞ²Ğ¸Ğ´ĞµĞ» Ğ”Ğ²Ğ¾Ñ€Ñ†Ğ¾Ğ²ÑƒÑ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ÑŒ, ĞŸĞµÑ‚Ñ€Ğ¾Ğ¿Ğ°Ğ²Ğ»Ğ¾Ğ²ÑĞºÑƒÑ ĞºÑ€ĞµĞ¿Ğ¾ÑÑ‚ÑŒ, ĞºÑ€Ñ‹ÑˆĞ¸ Ğ´Ğ¾Ğ¼Ğ¾Ğ², Ğ° Ğ½Ğ°Ğ´ ĞºÑ€Ñ‹ÑˆĞ°Ğ¼Ğ¸ Ğ»ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¿Ñ‚Ğ¸Ñ†Ñ‹. Ğ¢Ğ¾Ğ¼Ñƒ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ¿Ğ¾Ğ½Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°ÑÑŒ ÑĞºÑĞºÑƒÑ€ÑĞ¸Ñ. ĞĞ½ Ğ¿Ğ¾ÑĞ¾Ğ²ĞµÑ‚Ğ¾Ğ²Ğ°Ğ» Ğ´Ñ€ÑƒĞ·ÑŒÑĞ¼ Ğ¿Ğ¾ÑĞµÑ‚Ğ¸Ñ‚ÑŒ ÑĞ¾Ğ±Ğ¾Ñ€ Ğ¸ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ´Ğ½ÑÑ‚ÑŒÑÑ Ğ½Ğ° ĞºĞ¾Ğ»Ğ¾Ğ½Ğ½Ğ°Ğ´Ñƒ."""

DEFAULT_TEST_TEXT = "Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ ÑƒĞ»Ğ¸Ñ†Ğµ. Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°. Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾. Ğ¯ Ñ‡Ğ°ÑÑ‚Ğ¾ Ñ‡Ğ¸Ñ‚Ğ°Ñ ÑÑ‚Ñƒ ĞºĞ½Ğ¸Ğ³Ñƒ."

mystem = Mystem()
YOUTUBE_VIDEO_ID = "wJ65i_gDfT0" 
IMAGE_FILE_PATH = "banner.png"

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜ ---
def initialize_session_state():
    if "selected_words" not in st.session_state:
        st.session_state.selected_words = []
    if "clicked_word" not in st.session_state:
        st.session_state.clicked_word = None
    if "word_info" not in st.session_state:
        st.session_state.word_info = {}
    if "current_search_query" not in st.session_state:
        st.session_state.current_search_query = ""
    if "input_text_area" not in st.session_state:
        st.session_state.input_text_area = DEFAULT_TEST_TEXT
    if "translated_text" not in st.session_state:
        st.session_state.translated_text = ""
    if "last_processed_text" not in st.session_state:
        st.session_state.last_processed_text = ""
    if "last_processed_query" not in st.session_state:
        st.session_state.last_processed_query = ""

# ---------------------- 0.1. í˜ì´ì§€ ì„¤ì • ë° ë°°ë„ˆ ----------------------

initialize_session_state()
st.set_page_config(page_title="ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°", layout="wide")

try:
    st.image(IMAGE_FILE_PATH, use_column_width=True)
except FileNotFoundError:
    st.warning(f"ë°°ë„ˆ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ---------------------- 0.2. YouTube ì„ë² ë“œ í•¨ìˆ˜ ----------------------

def youtube_embed_html(video_id: str):
    embed_url = f"https://www.youtube.com/embed/{video_id}?autoplay=0&rel=0"
    return f"""
    <div class="video-container-wrapper">
        <div class="video-responsive">
            <iframe src="{embed_url}" frameborder="0" allowfullscreen></iframe>
        </div>
    </div>
    """

# ---------------------- í’ˆì‚¬ ë° í˜•íƒœì†Œ ë¶„ì„ ----------------------
POS_MAP = {
    'S': 'ëª…ì‚¬', 'V': 'ë™ì‚¬', 'A': 'í˜•ìš©ì‚¬', 'ADV': 'ë¶€ì‚¬', 'PR': 'ì „ì¹˜ì‚¬',
    'CONJ': 'ì ‘ì†ì‚¬', 'INTJ': 'ê°íƒ„ì‚¬', 'PART': 'ë¶ˆë³€í™”ì‚¬', 'NUM': 'ìˆ˜ì‚¬',
    'APRO': 'ëŒ€ëª…ì‚¬ì  í˜•ìš©ì‚¬', 'ANUM': 'ì„œìˆ˜ì‚¬', 'SPRO': 'ëŒ€ëª…ì‚¬',
    'PRICL': 'ë™ì‚¬ë¶€ì‚¬', 'COMP': 'ë¹„êµê¸‰', 'ADVB': 'ë¶€ì‚¬',
}

@st.cache_data(show_spinner=False)
def lemmatize_ru(word: str) -> str:
    if ' ' in word.strip(): return word.strip()
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        lemmas = mystem.lemmatize(word)
        return (lemmas[0] if lemmas else word).strip()
    return word

@st.cache_data(show_spinner=False)
def get_pos_ru(word: str) -> str:
    if ' ' in word.strip(): return 'êµ¬ í˜•íƒœ'
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        analysis = mystem.analyze(word)
        if analysis and 'analysis' in analysis[0] and analysis[0]['analysis']:
            grammar_info = analysis[0]['analysis'][0]['gr']
            pos_full = grammar_info.split(',')[0].strip()
            # Ğ±Ğ¾Ğ»ÑŒĞ½Ğ¸Ñ†Ğ° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë‚´ë¶€ ë¡œì§ (í•„ìš” ì‹œ ìœ ì§€)
            return POS_MAP.get(pos_full.split('=')[0], 'í’ˆì‚¬')
    return 'í’ˆì‚¬'

# ---------------------- 1. Gemini ì—°ë™ í•¨ìˆ˜ ----------------------

def get_word_info_schema(is_verb: bool):
    schema = {
        "type": "object",
        "properties": {
            "ko_meanings": {"type": "array", "items": {"type": "string"}},
            "examples": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "ru": {"type": "string"},
                        "ko": {"type": "string"}
                    },
                    "required": ["ru", "ko"]
                }
            }
        },
        "required": ["ko_meanings", "examples"]
    }
    if is_verb:
        schema['properties']['aspect_pair'] = {
            "type": "object",
            "properties": {"imp": {"type": "string"}, "perf": {"type": "string"}},
            "required": ["imp", "perf"]
        }
        schema['required'].append('aspect_pair')
    return schema

@st.cache_data(show_spinner=False, ttl=300) 
def fetch_from_gemini(word, lemma, pos):
    api_key = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY"))
    client = genai.Client(api_key=api_key) if api_key else None
    if not client: return {"ko_meanings": ["API í‚¤ ì—†ìŒ"], "examples": []}
    
    is_verb = (pos == 'ë™ì‚¬')
    config = {
        "system_instruction": "ë„ˆëŠ” ëŸ¬ì‹œì•„ì–´ í•™ìŠµ ë„ìš°ë¯¸ë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ë©°, 'Ğ±Ğ¾Ğ»ÑŒĞ½Ğ¸Ñ†Ğ°' ê°™ì€ ë‹¨ì–´ ì²˜ë¦¬ì— ìœ ì˜í•˜ë¼.",
        "response_mime_type": "application/json",
        "response_schema": get_word_info_schema(is_verb),
    }
    prompt = f"ë‹¨ì–´: {word}. ê¸°ë³¸í˜•: {lemma}. í’ˆì‚¬: {pos}."
    try:
        res = client.models.generate_content(model="gemini-2.0-flash", contents=prompt, config=config)
        return json.loads(res.text)
    except Exception as e:
        return {"ko_meanings": [f"ì˜¤ë¥˜: {str(e)}"], "examples": []}

# ---------------------- 2. í…ìŠ¤íŠ¸ ë²ˆì—­ í•¨ìˆ˜ ----------------------

@st.cache_data(show_spinner="ë²ˆì—­ ì¤‘...", ttl=600)
def translate_text(russian_text, highlight_words):
    api_key = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY"))
    client = genai.Client(api_key=api_key) if api_key else None
    if not client: return "API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    phrases = ", ".join([f"'{w}'" for w in highlight_words])
    prompt = f"ë²ˆì—­í•  í…ìŠ¤íŠ¸: '{russian_text}'. í•˜ì´ë¼ì´íŠ¸ ëŒ€ìƒ: {phrases}. í•œêµ­ì–´ ë²ˆì—­ ì‹œ ëŒ€ìƒ ë‹¨ì–´ëŠ” <PHRASE_START>...<PHRASE_END>ë¡œ ê°ì‹¸ì¤˜."
    
    try:
        res = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt,
            config={"system_instruction": "ë„ˆëŠ” ë²ˆì—­ê°€ë‹¤. ê²°ê³¼ë¬¼ì— ë¶€ì—°ì„¤ëª… ì—†ì´ ì˜¤ì§ ë²ˆì—­ë³¸ë§Œ ì¶œë ¥í•œë‹¤."}
        )
        translated = res.text.strip().replace("<PHRASE_START>", '<span class="word-selected">').replace("<PHRASE_END>", '</span>')
        return translated
    except Exception as e:
        return f"ë²ˆì—­ ì˜¤ë¥˜: {e}"

# ---------------------- 3. ì „ì—­ ìŠ¤íƒ€ì¼ ----------------------

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&display=swap');
    html, body, .stApp { font-family: 'Nanum Gothic', sans-serif !important; }
    .text-container { line-height: 2.0; font-size: 1.25em; margin-bottom: 20px; }
    .word-selected { color: #007bff !important; font-weight: bold; background-color: #e0f0ff; border-bottom: 3px solid #007bff; }
    .video-responsive { overflow: hidden; padding-bottom: 56.25%; position: relative; height: 0; }
    .video-responsive iframe { left: 0; top: 0; height: 100%; width: 100%; position: absolute; }
</style>
""", unsafe_allow_html=True)

# ---------------------- 4. UI ë°°ì¹˜ ë° ë¡œì§ ----------------------

def load_default_text():
    st.session_state.input_text_area = NEW_DEFAULT_TEXT
    st.session_state.translated_text = ""
    st.session_state.selected_words = []

st.subheader("ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸")
st.button("ì¤‘ê¸‰ëŸ¬ì‹œì•„ì–´ì—°ìŠµ í…ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°", on_click=load_default_text)

current_text = st.text_area(
    "ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
    value=st.session_state.input_text_area,
    height=150,
    key="input_text_area_widget"
)

# í…ìŠ¤íŠ¸ ë³€ê²½ ê°ì§€
if current_text != st.session_state.last_processed_text:
    st.session_state.input_text_area = current_text
    st.session_state.translated_text = ""
    st.session_state.last_processed_text = current_text

st.divider()
st.subheader("ë‹¨ì–´/êµ¬ ê²€ìƒ‰")
manual_input = st.text_input("ê²€ìƒ‰í•  ë‹¨ì–´ ë˜ëŠ” êµ¬ ì…ë ¥")

if manual_input and manual_input != st.session_state.last_processed_query:
    if manual_input not in st.session_state.selected_words:
        st.session_state.selected_words.append(manual_input)
    st.session_state.clicked_word = manual_input
    
    lemma = lemmatize_ru(manual_input)
    pos = get_pos_ru(manual_input)
    info = fetch_from_gemini(manual_input, lemma, pos)
    st.session_state.word_info[lemma] = {**info, "loaded_token": manual_input, "pos": pos}
    st.session_state.last_processed_query = manual_input

# ---------------------- 5. ë©”ì¸ ë ˆì´ì•„ì›ƒ ----------------------

left, right = st.columns([2, 1])

with left:
    st.subheader("ëŸ¬ì‹œì•„ì–´ ì›ë¬¸")
    # í•˜ì´ë¼ì´íŒ… ì ìš© ë¡œì§ (ê°„ëµí™”)
    display_html = current_text
    for word in sorted(st.session_state.selected_words, key=len, reverse=True):
        display_html = re.sub(f'({re.escape(word)})', r'<span class="word-selected">\1</span>', display_html)
    
    st.markdown(f'<div class="text-container">{display_html}</div>', unsafe_allow_html=True)
    
    if st.button("ì´ˆê¸°í™”"):
        initialize_session_state()
        st.rerun()

with right:
    st.subheader("ìƒì„¸ ì •ë³´")
    if st.session_state.clicked_word:
        token = st.session_state.clicked_word
        lemma = lemmatize_ru(token)
        info = st.session_state.word_info.get(lemma, {})
        
        st.markdown(f"### {token}")
        if info:
            st.write(f"**ê¸°ë³¸í˜•:** {lemma} ({info.get('pos')})")
            for m in info.get("ko_meanings", []):
                st.write(f"- {m}")
            st.divider()
            for ex in info.get("examples", []):
                st.caption(f"RU: {ex['ru']}")
                st.write(f"KO: {ex['ko']}")
    else:
        st.info("ë‹¨ì–´ë¥¼ ê²€ìƒ‰í•˜ë©´ ì •ë³´ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

# ---------------------- 6. í•˜ë‹¨ ê²°ê³¼ ----------------------

st.divider()
st.subheader("í•œêµ­ì–´ ë²ˆì—­ë³¸")
if not st.session_state.translated_text:
    st.session_state.translated_text = translate_text(current_text, st.session_state.selected_words)

st.markdown(f'<div class="text-container">{st.session_state.translated_text}</div>', unsafe_allow_html=True)

# í™ë³´ ì˜ìƒ
_, col_v = st.columns([1, 1])
with col_v:
    st.subheader("ğŸ¬ í”„ë¡œì íŠ¸ í™ë³´ ì˜ìƒ")
    st.markdown(youtube_embed_html(YOUTUBE_VIDEO_ID), unsafe_allow_html=True)

st.markdown("---")
st.caption(" ì´ í˜ì´ì§€ëŠ” ì—°ì„¸ëŒ€í•™êµ ë…¸ì–´ë…¸ë¬¸í•™ê³¼ 25-2 ëŸ¬ì‹œì•„ì–´ êµìœ¡ë¡  5íŒ€ì˜ í”„ë¡œì íŠ¸ ê²°ê³¼ë¬¼ì…ë‹ˆë‹¤. <br>  ë³¸ í˜ì´ì§€ì˜ ë‚´ìš©, ê¸°ëŠ¥ ë° ë°ì´í„°ë¥¼ í•™ìŠµ ëª©ì  ì´ì™¸ì˜ ìš©ë„ë¡œ ë¬´ë‹¨ ë³µì œ, ë°°í¬, ìƒì—…ì  ì´ìš©í•  ê²½ìš°,  ê´€ë ¨ ë²•ë ¹ì— ë”°ë¼ ë¯¼ì‚¬ìƒ ì†í•´ë°°ìƒ ì²­êµ¬ ë° í˜•ì‚¬ìƒ ì²˜ë²Œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
