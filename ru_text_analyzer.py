import streamlit as st
import re
import os
import json
import pandas as pd
from pymystem3 import Mystem
from google import genai
# vision í´ë¼ì´ì–¸íŠ¸ ì„í¬íŠ¸ ì œê±°
import io
import urllib.parse
from typing import Union

# ---------------------- 0. ì´ˆê¸° ì„¤ì • ë° ìƒìˆ˜ ----------------------

NEW_DEFAULT_TEXT = """Ğ¢Ğ¾Ğ¼ Ğ¶Ğ¸Ğ²Ñ‘Ñ‚ Ğ² Ğ¡Ğ°Ğ½ĞºÑ‚-ĞŸĞµÑ‚ĞµÑ€Ğ±ÑƒÑ€Ğ³Ğµ ÑƒĞ¶Ğµ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼ĞµÑÑÑ†ĞµĞ². Ğ’ ÑÑƒĞ±Ğ±Ğ¾Ñ‚Ñƒ, ĞºĞ¾Ğ³Ğ´Ğ° Ğ±Ñ‹Ğ»Ğ° Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ°, Ğ¢Ğ¾Ğ¼ Ñ€ĞµÑˆĞ¸Ğ» Ğ¿Ğ¾Ğ¹Ñ‚Ğ¸ Ğ² Ğ˜ÑĞ°Ğ°ĞºĞ¸ĞµĞ²ÑĞºĞ¸Ğ¹ ÑĞ¾Ğ±Ğ¾Ñ€. Ğ¢Ğ¾Ğ¼ Ğ´Ğ°Ğ²Ğ½Ğ¾ Ğ¼ĞµÑ‡Ñ‚Ğ°Ğ» Ğ¿Ğ¾Ğ±Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ² ÑÑ‚Ğ¾Ğ¼ ÑĞ¾Ğ±Ğ¾Ñ€Ğµ. Ğ˜ÑĞ°Ğ°ĞºĞ¸ĞµĞ²ÑĞºĞ¸Ğ¹ ÑĞ¾Ğ±Ğ¾Ñ€ â€” Ğ¾Ğ´Ğ½Ğ¾ Ğ¸Ğ· ÑĞ°Ğ¼Ñ‹Ñ… Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ñ… Ğ·Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ğ² Ğ¡Ğ°Ğ½ĞºÑ‚-ĞŸĞµÑ‚ĞµÑ€Ğ±ÑƒÑ€Ğ³Ğµ, ĞµĞ³Ğ¾ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑƒĞ²Ğ¸Ğ´ĞµÑ‚ÑŒ
Ğ´Ğ°Ğ¶Ğµ Ğ¸Ğ·Ğ´Ğ°ë ˆê°€. ĞšĞ¾Ğ³Ğ´Ğ° Ğ¢Ğ¾Ğ¼ Ğ³ÑƒĞ»ÑĞ» Ğ¿Ğ¾ Ñ†ĞµĞ½Ñ‚Ñ€Ñƒ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°, Ğ¾Ğ½ Ğ¾Ñ‚Ğ¾Ğ²ÑÑĞ´Ñƒ Ğ²Ğ¸Ğ´ĞµĞ» Ğ·Ğ¾Ğ»Ğ¾Ñ‚Ğ¾Ğ¹ ĞºÑƒĞ¿Ğ¾Ğ» ÑĞ¾Ğ±Ğ¾Ñ€Ğ°. Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¢Ğ¾Ğ¼ Ñ€ĞµÑˆĞ¸Ğ» Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ ÑĞ¾Ğ±Ğ¾Ñ€ ÑĞ½Ğ°Ñ€ÑƒĞ¶Ğ¸. ĞĞ½ Ğ¿Ñ€Ğ¸ÑˆÑ‘Ğ» Ğ½Ğ° Ğ˜ÑĞ°Ğ°ĞºĞ¸ĞµĞ²ÑĞºÑƒÑ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ÑŒ â€” Ğ¾Ñ‚ÑÑĞ´Ğ° Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¿Ñ€ĞµĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ğ²Ğ¸Ğ´ Ğ½Ğ° ÑĞ¾Ğ±Ğ¾Ñ€. ĞŸĞ¾Ñ‚Ğ¾Ğ¼ Ğ¢Ğ¾Ğ¼ Ğ¿Ğ¾Ğ´Ğ¾ÑˆÑ‘Ğ» Ğº ÑĞ¾Ğ±Ğ¾Ñ€Ñƒ Ğ¿Ğ¾Ğ±Ğ»Ğ¸Ğ¶Ğµ, Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµĞ» ĞµĞ³Ğ¾ ÑĞ¿ĞµÑ€ĞµĞ´Ğ¸, ÑĞ·Ğ°ë””, 2 Ñ€Ğ°Ğ·Ğ° Ğ¾Ğ±Ğ¾ÑˆÑ‘Ğ» Ğ²Ğ¾ĞºÑ€ÑƒĞ³ ÑĞ¾Ğ±Ğ¾Ñ€Ğ°, Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ Ğ²Ğ¾ÑˆÑ‘Ğ» Ğ²Ğ½ÑƒÑ‚Ñ€ÑŒ. Ğ’Ğ½ÑƒÑ‚Ñ€Ğ¸ ÑĞ¾Ğ±Ğ¾Ñ€ Ğ¾Ñ‡ĞµĞ½ÑŒ ĞºÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹. Ğ¢Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ», Ñ‡Ñ‚Ğ¾ ĞºÑƒĞ¿Ğ¾Ğ» ÑĞ¾Ğ±Ğ¾Ñ€Ğ° â€” Ñ‚Ñ€ĞµÑ‚Ğ¸Ğ¹ Ğ¿Ğ¾ Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ğ½Ğµ Ğ² Ğ•Ğ²Ñ€Ğ¾Ğ¿Ğµ. Ğ¢Ğ¾Ğ¼ Ğ¿Ğ¾Ğ´Ğ½ÑĞ» Ğ³Ğ¾Ğ»Ğ¾Ğ²Ñƒ Ğ²Ğ²ĞµÑ€Ñ… Ğ¸ ÑƒĞ²Ğ¸Ğ´ĞµĞ», Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ´ ĞºÑƒĞ¿Ğ¾Ğ»Ğ¾Ğ¼ Â«Ğ»ĞµÑ‚Ğ°ĞµÑ‚Â» ÑĞµÑ€ĞµĞ±Ñ€ÑĞ½Ñ‹Ğ¹ Ğ³Ğ¾Ğ»ÑƒĞ±ÑŒ. Ğ¢Ğ¾Ğ¼ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµĞ» Ğ²Ğ¾ĞºÑ€ÑƒĞ³: Ğ²Ğ¿ĞµÑ€ĞµĞ´Ğ¸, ÑĞ·Ğ°Ğ´Ğ¸, ÑĞ¿Ñ€Ğ°Ğ²Ğ°, ÑĞ»ĞµĞ²Ğ° â€” Ğ²ĞµĞ·Ğ´Ğµ Ğ±Ñ‹Ğ»Ğ¸ ĞºÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğµ Ğ¸ĞºĞ¾Ğ½Ñ‹.
ĞŸĞ¾Ñ‚Ğ¾Ğ¼ Ğ¢Ğ¾Ğ¼ Ñ€ĞµÑˆĞ¸Ğ» Ğ¿Ğ¾Ğ´Ğ½ÑÑ‚ÑŒÑÑ Ğ½Ğ° ĞºĞ¾Ğ»Ğ¾Ğ½Ğ½Ğ°Ğ´Ñƒ ÑĞ¾Ğ±Ğ¾Ñ€Ğ°. Ğ’ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ´ĞµĞ½ÑŒ Ğ² ÑĞ¾Ğ±Ğ¾Ñ€Ğµ Ğ±Ñ‹Ğ»Ğ¾ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ÑƒÑ€Ğ¸ÑÑ‚Ğ¾Ğ²: Ğ¾Ğ´Ğ½Ğ¸ Ğ¿Ğ¾Ğ´Ğ½Ğ¸Ğ¼Ğ°Ğ»Ğ¸ÑÑŒ Ğ²Ğ²ĞµÑ€Ñ…, Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ ÑĞ¿ÑƒÑĞºĞ°Ğ»Ğ¸ÑÑŒ Ğ²Ğ½Ğ¸Ğ·. Ğ¢Ğ¾Ğ¼ Ñ‚Ğ¾Ğ¶Ğµ Ğ¿Ğ¾Ğ´Ğ½ÑĞ»ÑÑ Ğ²Ğ²ĞµÑ€Ñ…. ĞÑ‚Ñ‚ÑƒĞ´Ğ°, ÑĞ²ĞµÑ€Ñ…Ñƒ, Ñ Ğ²Ñ‹ÑĞ¾Ñ‚Ñ‹ 43 (ÑĞ¾Ñ€Ğ¾ĞºĞ° Ñ‚Ñ€Ñ‘Ñ…) Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ², Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ¿Ñ€ĞµĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ğ²Ğ¸Ğ´ Ğ½Ğ° Ñ†ĞµĞ½Ñ‚Ñ€ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°. Ğ¢Ğ¾Ğ¼ ÑƒĞ²Ğ¸Ğ´ĞµĞ» Ğ”Ğ²Ğ¾Ñ€Ñ†Ğ¾Ğ²ÑƒÑ Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ÑŒ, ĞŸĞµÑ‚Ñ€Ğ¾Ğ¿Ğ°Ğ²Ğ»Ğ¾Ğ²ÑĞºÑƒÑ ĞºÑ€ĞµĞ¿Ğ¾ÑÑ‚ÑŒ, ĞºÑ€Ñ‹ÑˆĞ¸ Ğ´Ğ¾Ğ¼Ğ¾Ğ², Ğ° Ğ½Ğ°Ğ´ ĞºÑ€Ñ‹ÑˆĞ°Ğ¼Ğ¸ Ğ»ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¿Ñ‚Ğ¸Ñ†Ñ‹.
Ğ¢Ğ¾Ğ¼Ñƒ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ¿Ğ¾Ğ½Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ°ÑÑŒ ÑĞºÑĞºÑƒÑ€ÑĞ¸Ñ. ĞĞ½ Ğ¿Ğ¾ÑĞ¾Ğ²ĞµÑ‚Ğ¾Ğ²Ğ°Ğ» Ğ´Ñ€ÑƒĞ·ÑŒÑĞ¼ Ğ¿Ğ¾ÑĞµÑ‚Ğ¸Ñ‚ÑŒ ÑĞ¾Ğ±Ğ¾Ñ€ Ğ¸ Ğ¾Ğ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ´Ğ½ÑÑ‚ÑŒÑÑ Ğ½Ğ° ĞºĞ¾Ğ»Ğ¾Ğ½Ğ½Ğ°ë‘."""

DEFAULT_TEST_TEXT = "Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ ÑƒĞ»Ğ¸Ñ†Ğµ. Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°. Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾. Ğ¯ Ñ‡Ğ°ÑÑ‚Ğ¾ Ñ‡Ğ¸Ñ‚Ğ°Ñ ÑÑ‚Ñƒ ĞºĞ½Ğ¸Ğ³Ñƒ."

mystem = Mystem()
YOUTUBE_VIDEO_ID = "wJ65i_gDfT0" 
IMAGE_FILE_PATH = "banner.png"

def initialize_session_state():
    if "selected_words" not in st.session_state:
        st.session_state.selected_words = []
    if "clicked_word" not in st.session_state:
        st.session_state.clicked_word = None
    if "word_info" not in st.session_state:
        st.session_state.word_info = {}
    if "current_search_query" not in st.session_state:
        st.session_state.current_search_query = ""
    # ocr_output_textëŠ” ë‹¤ë¥¸ ë¡œì§ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€í•˜ë˜ UIì—ì„  ì œê±°
    if "ocr_output_text" not in st.session_state:
        st.session_state.ocr_output_text = ""
    if "input_text_area" not in st.session_state:
        st.session_state.input_text_area = DEFAULT_TEST_TEXT
    if "translated_text" not in st.session_state:
        st.session_state.translated_text = ""
    if "last_processed_text" not in st.session_state:
        st.session_state.last_processed_text = ""
    if "last_processed_query" not in st.session_state:
        st.session_state.last_processed_query = ""

initialize_session_state()
st.set_page_config(page_title="ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°", layout="wide")

# ìƒë‹¨ ë°°ë„ˆ ì´ë¯¸ì§€ëŠ” ìœ ì§€
try:
    st.image(IMAGE_FILE_PATH, use_column_width=True)
except FileNotFoundError:
    st.markdown("### ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œìŠ¤í…œ")

# ---------------------- 0.2. YouTube ì„ë² ë“œ í•¨ìˆ˜ (ìœ ì§€) ----------------------
def youtube_embed_html(video_id: str):
    embed_url = f"https://www.youtube.com/embed/{video_id}?autoplay=0&rel=0"
    return f'<div class="video-container-wrapper"><div class="video-responsive"><iframe src="{embed_url}" frameborder="0" allowfullscreen></iframe></div></div>'

# ---------------------- í’ˆì‚¬ ë³€í™˜ ë° Mystem í•¨ìˆ˜ (ìœ ì§€) ----------------------
POS_MAP = {
    'S': 'ëª…ì‚¬', 'V': 'ë™ì‚¬', 'A': 'í˜•ìš©ì‚¬', 'ADV': 'ë¶€ì‚¬', 'PR': 'ì „ì¹˜ì‚¬',
    'CONJ': 'ì ‘ì†ì‚¬', 'INTJ': 'ê°íƒ„ì‚¬', 'PART': 'ë¶ˆë³€í™”ì‚¬', 'NUM': 'ìˆ˜ì‚¬',
    'APRO': 'ëŒ€ëª…ì‚¬ì  í˜•ìš©ì‚¬', 'ANUM': 'ì„œìˆ˜ì‚¬', 'SPRO': 'ëŒ€ëª…ì‚¬',
    'PRICL': 'ë™ì‚¬ë¶€ì‚¬', 'COMP': 'ë¹„êµê¸‰', 'A=cmp': 'ë¹„êµê¸‰ í˜•ìš©ì‚¬', 'ADV=cmp': 'ë¹„êµê¸‰ ë¶€ì‚¬',
    'ADVB': 'ë¶€ì‚¬', 'NONLEX': 'ë¹„ë‹¨ì–´', 'INIT': 'ë¨¸ë¦¬ê¸€ì', 'P': 'ë¶ˆë³€í™”ì‚¬/ì „ì¹˜ì‚¬', 'ADJ': 'í˜•ìš©ì‚¬', 'N': 'ëª…ì‚¬',
}

@st.cache_data(show_spinner=False)
def lemmatize_ru(word: str) -> str:
    if ' ' in word.strip(): return word.strip()
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        lemmas = mystem.lemmatize(word)
        return (lemmas[0] if lemmas else word).strip()
    return word

@st.cache_data(show_spinner=False)
def get_pos_ru(word: str) -> str:
    if ' ' in word.strip(): return 'êµ¬ í˜•íƒœ'
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        analysis = mystem.analyze(word)
        if analysis and 'analysis' in analysis[0] and analysis[0]['analysis']:
            grammar_info = analysis[0]['analysis'][0]['gr']
            parts = re.split(r'[,=]', grammar_info, 1)
            pos_abbr_base = parts[0].strip()
            pos_full = grammar_info.split(',')[0].strip()
            if pos_full in POS_MAP: return POS_MAP[pos_full]
            return POS_MAP.get(pos_abbr_base, 'í’ˆì‚¬')
    return 'í’ˆì‚¬'

# ---------------------- 1. Gemini ì—°ë™ í•¨ìˆ˜ (í•µì‹¬ API í˜¸ì¶œë¶€ ìœ ì§€) ----------------------
def get_gemini_client():
    api_key = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY"))
    return genai.Client(api_key=api_key) if api_key else None

def get_word_info_schema(is_verb: bool):
    schema = {
        "type": "object",
        "properties": {
            "ko_meanings": {"type": "array", "items": {"type": "string"}},
            "examples": {"type": "array", "items": {"type": "object", "properties": {"ru": {"type": "string"}, "ko": {"type": "string"}}, "required": ["ru", "ko"]}}
        },
        "required": ["ko_meanings", "examples"]
    }
    if is_verb:
        schema['properties']['aspect_pair'] = {"type": "object", "properties": {"imp": {"type": "string"}, "perf": {"type": "string"}}, "required": ["imp", "perf"]}
        schema['required'].append('aspect_pair')
    return schema

@st.cache_data(show_spinner=False, ttl=300) 
def fetch_from_gemini(word, lemma, pos):
    client = get_gemini_client()
    if not client: return {"ko_meanings": ["API í‚¤ ì—†ìŒ"], "examples": []}
    is_verb = (pos == 'ë™ì‚¬')
    config = {"system_instruction": "ë„ˆëŠ” ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ í•™ìŠµ ë„ìš°ë¯¸ì´ë‹¤. JSONìœ¼ë¡œë§Œ ë‹µí•œë‹¤.", "response_mime_type": "application/json", "response_schema": get_word_info_schema(is_verb)}
    prompt = f"ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´: {word}. ê¸°ë³¸í˜•: {lemma}. í’ˆì‚¬: {pos}. ì •ë³´ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤."
    try:
        res = client.models.generate_content(model="gemini-2.0-flash", contents=prompt, config=config)
        return json.loads(res.text)
    except Exception as e:
        return {"ko_meanings": [f"API ì˜¤ë¥˜: {str(e)}"], "examples": []}

@st.cache_data(show_spinner="ë²ˆì—­ ì¤‘...", ttl=600)
def translate_text(russian_text, highlight_words):
    client = get_gemini_client()
    if not client: return "API í‚¤ ì—†ìŒ"
    phrases = ", ".join([f"'{w}'" for w in highlight_words])
    prompt = f"ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸: '{russian_text}' ë²ˆì—­. ê°•ì¡° ë‹¨ì–´: {phrases}. <PHRASE_START>, <PHRASE_END> ë§ˆí¬ì—… ì‚¬ìš©."
    try:
        res = client.models.generate_content(model="gemini-2.0-flash", contents=prompt, config={"system_instruction": "ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë²ˆì—­ê¸°."})
        translated = res.text.strip().replace("<PHRASE_START>", '<span class="word-selected">').replace("<PHRASE_END>", '</span>')
        return translated
    except Exception as e: return f"ë²ˆì—­ ì˜¤ë¥˜: {e}"

# ---------------------- 3. ìŠ¤íƒ€ì¼ ë° UI ë¡œì§ ----------------------
st.markdown("""<style>
    @import url('https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&display=swap');
    html, body, .stApp { font-family: 'Nanum Gothic', sans-serif !important; }
    .text-container { line-height: 2.0; font-size: 1.25em; margin-bottom: 20px; }
    .word-selected { color: #007bff !important; font-weight: bold; background-color: #e0f0ff; padding: 2px 0px; border-bottom: 3px solid #007bff; border-radius: 2px; }
</style>""", unsafe_allow_html=True)

def load_default_text():
    st.session_state.input_text_area = NEW_DEFAULT_TEXT
    st.session_state.translated_text = ""
    st.session_state.selected_words = []

# --- OCR ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„¹ì…˜ë§Œ ì‚­ì œë¨ ---
st.button("ì¤‘ê¸‰ëŸ¬ì‹œì•„ì–´ì—°ìŠµ í…ìŠ¤íŠ¸ ë°˜ì˜í•˜ê¸°(êµì¬ 2ê¶Œ 44í˜ì´ì§€)", on_click=load_default_text)

st.subheader("ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸")
current_text = st.text_area("ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì„¸ìš”", value=st.session_state.input_text_area, height=150, key="input_text_area")

if current_text != st.session_state.last_processed_text:
    st.session_state.translated_text = ""
    st.session_state.selected_words = []
    st.session_state.word_info = {}

# --- ë‹¨ì–´ ê²€ìƒ‰ ë° ìƒì„¸ ì •ë³´ ë¡œì§ (ìœ ì§€) ---
st.divider()
manual_input = st.text_input("ë‹¨ì–´ ë˜ëŠ” êµ¬ë¥¼ ì…ë ¥í•˜ê³  Enter", key="current_search_query")
if manual_input and manual_input != st.session_state.get("last_processed_query"):
    if manual_input not in st.session_state.selected_words:
        st.session_state.selected_words.append(manual_input)
    st.session_state.clicked_word = manual_input
    lemma = lemmatize_ru(manual_input)
    pos = get_pos_ru(manual_input)
    info = fetch_from_gemini(manual_input, lemma, pos)
    st.session_state.word_info[lemma] = {**info, "loaded_token": manual_input, "pos": pos}
    st.session_state.last_processed_query = manual_input

# --- ë ˆì´ì•„ì›ƒ ì¶œë ¥ (ìœ ì§€) ---
left, right = st.columns([2, 1])
with left:
    st.subheader("ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ì›ë¬¸")
    # ì›ë¬¸ í•˜ì´ë¼ì´íŒ… ë¡œì§ ì ìš©
    display_html = current_text
    for phrase in sorted(st.session_state.selected_words, key=len, reverse=True):
        display_html = re.sub(f'({re.escape(phrase)})', r'<span class="word-selected">\1</span>', display_html)
    st.markdown(f'<div class="text-container">{display_html}</div>', unsafe_allow_html=True)

with right:
    st.subheader("ë‹¨ì–´ ìƒì„¸ ì •ë³´")
    if st.session_state.clicked_word:
        token = st.session_state.clicked_word
        lemma = lemmatize_ru(token)
        info = st.session_state.word_info.get(lemma, {})
        if info:
            st.markdown(f"### **{token}**")
            st.write(f"ê¸°ë³¸í˜•: {lemma} / í’ˆì‚¬: {info.get('pos')}")
            st.write("ëœ»:", ", ".join(info.get("ko_meanings", [])))
    else: st.info("ë‹¨ì–´ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.")

# ë²ˆì—­ë³¸ ë° í•˜ë‹¨ ì˜ìƒ ìœ ì§€
st.divider()
st.subheader("í•œêµ­ì–´ ë²ˆì—­ë³¸")
if not st.session_state.translated_text:
    st.session_state.translated_text = translate_text(current_text, st.session_state.selected_words)
    st.session_state.last_processed_text = current_text
st.markdown(f'<div class="text-container" style="color: #333;">{st.session_state.translated_text}</div>', unsafe_allow_html=True)

# í™ë³´ ì˜ìƒ ë ˆì´ì•„ì›ƒ (ìœ ì§€)
_, col_video = st.columns([1, 1])
with col_video:
    st.subheader("ğŸ¬ í”„ë¡œì íŠ¸ í™ë³´ ì˜ìƒ")
    st.markdown(youtube_embed_html(YOUTUBE_VIDEO_ID), unsafe_allow_html=True)

st.caption("Â© ì—°ì„¸ëŒ€í•™êµ ë…¸ì–´ë…¸ë¬¸í•™ê³¼ í”„ë¡œì íŠ¸")
