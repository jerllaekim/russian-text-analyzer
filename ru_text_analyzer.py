import os
import re
import json
import html
import urllib.parse

import pandas as pd
import streamlit as st
from pymystem3 import Mystem
# google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
# pip install google-generativeai
try:
    import google.generativeai as genai
except ImportError:
    st.error("google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install google-generativeai'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    st.stop()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì • + ì „ì—­ ìƒíƒœ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°", layout="wide")
st.title("ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°")

if "clicked_word" not in st.session_state:
    st.session_state.clicked_word = None          # í˜„ì¬ ìƒì„¸ë³´ê¸° ì¤‘ì¸ ë‹¨ì–´(í‘œë©´í˜•)
if "selected_words" not in st.session_state:
    st.session_state.selected_words = []          # ì‚¬ìš©ìê°€ ì„ íƒí•œ ë‹¨ì–´(í‘œë©´í˜•) ë¦¬ìŠ¤íŠ¸
if "word_info" not in st.session_state:
    # lemma ê¸°ì¤€ìœ¼ë¡œ ëœ»ì„ ëˆ„ì  ì €ì¥
    # ì˜ˆ: {"Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº": {"lemma": "Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº", "ko_meanings": ["ì‚¬ëŒ", "ì¸ê°„"]}, ...}
    st.session_state.word_info = {}


# ì„ íƒ ë‹¨ì–´ ì¹©ìš© CSS
st.markdown(
    """
<style>
div.selected-word-chip > button {
    border-radius: 999px;
    padding: 2px 10px;
    margin: 3px;
    border: 1px solid #1E88E5;
    background-color: rgba(30, 136, 229, 0.06);
}
div.selected-word-chip-active > button {
    border-radius: 999px;
    padding: 2px 10px;
    margin: 3px;
    border: 1px solid #1E88E5;
    background-color: rgba(30, 136, 229, 0.18);
}
</style>
""",
    unsafe_allow_html=True,
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜•íƒœì†Œ ë¶„ì„ê¸° (lemma)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Mystem()ì€ ì´ˆê¸°í™”ì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìºì‹œí•©ë‹ˆë‹¤.
@st.cache_resource
def get_mystem():
    return Mystem()

mystem = get_mystem()

@st.cache_data(show_spinner=False)
def lemmatize_ru(word: str) -> str:
    lemmas = mystem.lemmatize(word)
    return (lemmas[0] if lemmas else word).strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini API ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit Secretsì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
api_key = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY"))

if not api_key:
    st.error("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. Streamlit Secretsì— GEMINI_API_KEYë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    client = genai.GenerativeModel(model_name="gemini-1.5-flash")
    genai.configure(api_key=api_key)
except Exception as e:
    st.error(f"Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    st.stop()

SYSTEM_INSTRUCTION = """
ë„ˆëŠ” ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ í•™ìŠµì„ ë•ëŠ” ë„ìš°ë¯¸ì´ë‹¤.
ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´ì— ëŒ€í•´ ê°„ë‹¨í•œ í•œêµ­ì–´ ëœ»ê³¼ ì˜ˆë¬¸ì„ ì œê³µí•œë‹¤.
ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•´ì•¼ í•œë‹¤.
"""

def build_prompt(word: str, lemma: str) -> str:
    return f"""
{SYSTEM_INSTRUCTION}

ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´: {word}
ê¸°ë³¸í˜•(lemma): {lemma}

ë‹¤ìŒ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•´ë¼:

{{
  "ko_meanings": ["ëœ»1", "ëœ»2"],
  "examples": [
    {{
      "ru": "ëŸ¬ì‹œì•„ì–´ ì˜ˆë¬¸1 (ë‹¨ì–´ ë˜ëŠ” lemma í¬í•¨)",
      "ko": "ì˜ˆë¬¸1ì˜ í•œêµ­ì–´ ë²ˆì—­"
    }},
    {{
      "ru": "ëŸ¬ì‹œì•„ì–´ ì˜ˆë¬¸2 (ë‹¨ì–´ ë˜ëŠ” lemma í¬í•¨)",
      "ko": "ì˜ˆë¬¸2ì˜ í•œêµ­ì–´ ë²ˆì—­"
    }}
  ]
}}

ìš”êµ¬ì‚¬í•­:
- "ko_meanings"ì—ëŠ” ë„ˆë¬´ ê¸¸ì§€ ì•Šì€ í•œêµ­ì–´ ëœ» 1~3ê°œë¥¼ ë„£ì–´ë¼.
- "examples"ì—ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ 2ê°œë¥¼ ë„£ì–´ë¼.
- ê° ì˜ˆë¬¸ì—ëŠ” ë°˜ë“œì‹œ ì´ ë‹¨ì–´(ë˜ëŠ” í˜•íƒœ ë³€í™”ëœ í˜•íƒœ)ë¥¼ í¬í•¨í•´ì•¼ í•œë‹¤.
- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ê³ , ê·¸ ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆë¼.
"""

# Gemini API í˜¸ì¶œ í•¨ìˆ˜ (st.cache_data ì‚¬ìš©)
@st.cache_data(show_spinner=False)
def build_prompt(word: str, lemma: str) -> str:
    return f"""
{SYSTEM_INSTRUCTION}

ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´: {word}
ê¸°ë³¸í˜•(lemma): {lemma}

ë‹¤ìŒ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•´ë¼:

{{
  "ko_meanings": ["ëœ»1", "ëœ»2"],
  "examples": [
    {{
      "ru": "ëŸ¬ì‹œì•„ì–´ ì˜ˆë¬¸1 (ë‹¨ì–´ ë˜ëŠ” lemma í¬í•¨)",
      "ko": "ì˜ˆë¬¸1ì˜ í•œêµ­ì–´ ë²ˆì—­"
    }},
    {{
      "ru": "ëŸ¬ì‹œì•„ì–´ ì˜ˆë¬¸2 (ë‹¨ì–´ ë˜ëŠ” lemma í¬í•¨)",
      "ko": "ì˜ˆë¬¸2ì˜ í•œêµ­ì–´ ë²ˆì—­"
    }}
  ]
}}

ìš”êµ¬ì‚¬í•­:
- "ko_meanings"ì—ëŠ” ë„ˆë¬´ ê¸¸ì§€ ì•Šì€ í•œêµ­ì–´ ëœ» 1~3ê°œë¥¼ ë„£ì–´ë¼.
- "examples"ì—ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ 2ê°œë¥¼ ë„£ì–´ë¼.
- ê° ì˜ˆë¬¸ì—ëŠ” ë°˜ë“œì‹œ ì´ ë‹¨ì–´(ë˜ëŠ” í˜•íƒœ ë³€í™”ëœ í˜•íƒœ)ë¥¼ í¬í•¨í•´ì•¼ í•œë‹¤.
- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ê³ , ê·¸ ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆë¼.
"""

# Gemini API í˜¸ì¶œ í•¨ìˆ˜ (st.cache_data ì‚¬ìš©) - (â­ï¸ ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™” â­ï¸)
@st.cache_data(show_spinner=False)
def fetch_from_gemini(word: str, lemma: str):
    try:
        prompt = build_prompt(word, lemma)
        response = client.generate_content(contents=prompt)
        text = response.text.strip()

        # ```json ... ``` ë¡œ ê°ì‹¸ì ¸ ì˜¤ëŠ” ê²½ìš° ì œê±°
        if text.startswith("```"):
            text = text.strip("`")
            lines = text.splitlines()
            if lines and lines[0].lower().startswith("json"):
                text = "\n".join(lines[1:])

        # JSON íŒŒì‹± ì‹œë„
        data = json.loads(text)
        return data

    except json.JSONDecodeError as e:
        # ì˜¤ë¥˜ 1: Geminiê°€ JSONì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸(ì˜ˆ: "ì£„ì†¡í•©ë‹ˆë‹¤")ë¥¼ ë°˜í™˜
        st.error(f"API ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ (JSON ì•„ë‹˜): {e}\n\n[Gemini ì‘ë‹µ ì›ë¬¸]\n{text}")
        return {}
    except Exception as e:
        # ì˜¤ë¥˜ 2: ê·¸ ì™¸ ëª¨ë“  ì˜¤ë¥˜ (API í‚¤, ì¸ì¦, í• ë‹¹ëŸ‰ ë“±)
        st.error(f"Gemini API í˜¸ì¶œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ:\n{e}")
        return {}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# URL ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ê¸°ë°˜ í´ë¦­ ì²˜ë¦¬ (â­ï¸ ìˆ˜ì •ë¨ â­ï¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
params = st.query_params
clicked_from_url = None
if "w" in params:
    # [ìˆ˜ì •] .get() ë˜ëŠ” ì§ì ‘ ì ‘ê·¼ì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ë¬¸ìì—´ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    # params["w"][0] (X) -> params["w"] (O)
    clicked_from_url = params["w"]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í…ìŠ¤íŠ¸ ì…ë ¥
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
text = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", "Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ ÑƒĞ»Ğ¸Ñ†Ğµ. Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°.")

left, right = st.columns([2, 1], gap="large")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì™¼ìª½ ì˜ì—­ â€” ì›ë¬¸ í…ìŠ¤íŠ¸ (ì¸ë¼ì¸ í•˜ì´í¼ë§í¬) (â­ï¸ ìˆ˜ì •ë¨ â­ï¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with left:
    st.subheader("í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼")
    st.caption("ë‹¨ì–´ë¥¼ í´ë¦­í•˜ë©´ ì˜¤ë¥¸ìª½ì— ê¸°ë³¸í˜•, ëœ», ì˜ˆë¬¸ì´ í‘œì‹œë˜ê³ , ì•„ë˜ â€˜ì„ íƒí•œ ë‹¨ì–´ ëª¨ìŒâ€™ì— ëˆ„ì ë©ë‹ˆë‹¤.")

    # [ì¤‘ìš”] URLì—ì„œ ì½ì€ ë‹¨ì–´ë¥¼ ì„¸ì…˜ ìƒíƒœì— ë°˜ì˜
    # ì´ ë¡œì§ì€ ìŠ¤í¬ë¦½íŠ¸ê°€ ë‹¤ì‹œ ì‹¤í–‰ë  ë•Œ ê°€ì¥ ë¨¼ì € ì²˜ë¦¬ë©ë‹ˆë‹¤.
    if clicked_from_url:
        st.session_state.clicked_word = clicked_from_url
        if clicked_from_url not in st.session_state.selected_words:
            # selected_wordsëŠ” ì„¸ì…˜ì— ì €ì¥ë˜ë¯€ë¡œ ëˆ„ì ë©ë‹ˆë‹¤.
            st.session_state.selected_words.append(clicked_from_url)

    # í…ìŠ¤íŠ¸ë¥¼ word / non-word ë‹¨ìœ„ë¡œ split
    segments = re.split(r'(\w+)', text, flags=re.UNICODE)

    html_parts = []
    for seg in segments:
        if not seg:
            continue
        if re.fullmatch(r'\w+', seg, flags=re.UNICODE):
            word = seg
            # ì•„ì§ ì„ íƒë˜ì§€ ì•Šì€ ë‹¨ì–´ëŠ” ê²€ì€ìƒ‰, ì„ íƒëœ ë‹¨ì–´ëŠ” íŒŒë€ìƒ‰
            if word in st.session_state.selected_words:
                color = "#1E88E5"
                font_weight = "600"
            else:
                color = "#000000"
                font_weight = "400"
            href = f"?w={urllib.parse.quote_plus(word)}"
            
            # [ìˆ˜ì •] target="_self" ë¥¼ ì¶”ê°€í•˜ì—¬ ìƒˆ íƒ­ì´ ì•„ë‹Œ í˜„ì¬ íƒ­ì—ì„œ ì—´ë¦¬ë„ë¡ ê°•ì œ
            # ì´ê²ƒì´ ì—†ìœ¼ë©´ ìƒˆ íƒ­ì´ ì—´ë¦¬ê³  ì„¸ì…˜ì´ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
            html_parts.append(
                f'<a href="{href}" target="_self" style="color:{color}; font-weight:{font_weight}; text-decoration:none;">'
                f'{html.escape(word)}</a>'
            )
        else:
            html_parts.append(html.escape(seg))

    html_text = "".join(html_parts)
    st.markdown(html_text, unsafe_allow_html=True)

    with st.expander("ì´ˆê¸°í™”"):
        if st.button("ğŸ”„ ì„ íƒ & ëˆ„ì  ë°ì´í„° ì´ˆê¸°í™”"):
            st.session_state.clicked_word = None
            st.session_state.selected_words = []
            st.session_state.word_info = {}
            st.query_params.clear()
            st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì˜¤ë¥¸ìª½ ì˜ì—­ â€” í˜„ì¬ ì„ íƒ ë‹¨ì–´ ìƒì„¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with right:
    st.subheader("ğŸ“š ë‹¨ì–´ ì •ë³´")
    cw = st.session_state.clicked_word

    if cw:
        lemma = lemmatize_ru(cw)
        st.markdown(f"**ì„ íƒëœ ë‹¨ì–´:** {cw}")
        st.markdown(f"**ê¸°ë³¸í˜•(lemma):** *{lemma}*")

        try:
            # API í˜¸ì¶œ
            info = fetch_from_gemini(cw, lemma)
            ko_meanings = info.get("ko_meanings", [])
            examples = info.get("examples", [])
        except Exception as e:
            st.error(f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            ko_meanings = []
            examples = []

        # word_info ì„¸ì…˜ì— lemma ê¸°ì¤€ìœ¼ë¡œ ëˆ„ì  ì €ì¥
        if ko_meanings:
            st.session_state.word_info[lemma] = {
                "lemma": lemma,
                "ko_meanings": ko_meanings,
            }

        # í•œêµ­ì–´ ëœ» í‘œì‹œ
        if ko_meanings:
            st.markdown("**í•œêµ­ì–´ ëœ»:**")
            for m in ko_meanings:
                st.markdown(f"- {m}")
        else:
            st.write("í•œêµ­ì–´ ëœ»ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì˜ˆë¬¸ í‘œì‹œ
        if examples:
            st.markdown("### ğŸ“– ì˜ˆë¬¸")
            for ex in examples:
                ru = ex.get("ru", "")
                ko = ex.get("ko", "")
                if ru:
                    st.markdown(f"- **{ru}**")
                if ko:
                    st.markdown(f"â€ƒâ†’ {ko}")
        else:
            st.write("ì˜ˆë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ğŸ” ì™¸ë¶€ ì‚¬ì „ / ì½”í¼ìŠ¤ ë§í¬
        st.markdown("### ğŸ”— ì™¸ë¶€ ì‚¬ì „ / ì½”í¼ìŠ¤ ê²€ìƒ‰")
        lemma_for_link = lemma or cw
        mt_url = f"https://www.multitran.com/m.exe?l1=2&l2=5&s={lemma_for_link}"
        rnc_url = f"https://ruscorpora.ru/search?search={lemma_for_link}"
        st.markdown(f"[Multitranì—ì„œ ê²€ìƒ‰]({mt_url})  \n[ëŸ¬ì‹œì•„ êµ­ë¦½ ì½”í¼ìŠ¤ì—ì„œ ê²€ìƒ‰]({rnc_url})")

    else:
        st.info("ì™¼ìª½ í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ë¥¼ í´ë¦­í•˜ë©´ ì—¬ê¸° ì •ë³´ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•˜ë‹¨ â€” ì„ íƒí•œ ë‹¨ì–´ ëª¨ìŒ (ì¹© + í‘œ + CSV)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.divider()
st.subheader("ğŸ“ ì„ íƒí•œ ë‹¨ì–´ ëª¨ìŒ")

selected = st.session_state.selected_words
cw = st.session_state.clicked_word
word_info = st.session_state.word_info

if not selected: # 'selected_words' ê¸°ì¤€ìœ¼ë¡œ í‘œì‹œ
    st.caption("ì•„ì§ í´ë¦­í•´ì„œ ëˆ„ì ëœ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ë¥¼ í´ë¦­í•´ë³´ì„¸ìš”.")
else:
    # 1) ì¹© í˜•íƒœë¡œ ì„ íƒ ë‹¨ì–´ë“¤
    cols = st.columns(min(4, len(selected)))
    for idx, w in enumerate(selected):
        col = cols[idx % len(cols)]
        with col:
            # í˜„ì¬ í´ë¦­ëœ ë‹¨ì–´(cw)ì™€ ì¹©ì˜ ë‹¨ì–´(w)ê°€ ê°™ìœ¼ë©´ í™œì„±(active) ìŠ¤íƒ€ì¼
            is_active = (w == cw)
            chip_class = "selected-word-chip-active" if is_active else "selected-word-chip"
            label = f"âœ… {w}" if is_active else w
            
            st.markdown(f'<div class="{chip_class}">', unsafe_allow_html=True)
            if st.button(label, key=f"sel_chip_{w}"):
                # ì¹©ì„ í´ë¦­í•˜ë©´ í•´ë‹¹ ë‹¨ì–´ë¥¼ 'í˜„ì¬ í´ë¦­ëœ ë‹¨ì–´'ë¡œ ì„¤ì •í•˜ê³ 
                # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•œ ë’¤ ìƒˆë¡œê³ ì¹¨(rerun)
                st.query_params["w"] = w
                st.rerun()
            st.markdown('</div>', unsafe_allow_html=True)

    # 2) lemma / í•œêµ­ì–´ ëœ» ìš”ì•½ í‘œ + CSV (word_info ê¸°ì¤€)
    if word_info:
        rows = []
        # ëˆ„ì ëœ selected_words ìˆœì„œëŒ€ë¡œ word_infoì—ì„œ ì •ë³´ ì°¾ê¸°
        # (ì¤‘ë³µ lemma ì œê±°ë¥¼ ìœ„í•´ set ì‚¬ìš©)
        added_lemmas = set()
        
        # ë¨¼ì € í˜„ì¬ í´ë¦­ëœ ë‹¨ì–´ì˜ lemmaë¥¼ ë§¨ ìœ„ì— ì¶”ê°€ (ìˆë‹¤ë©´)
        if cw:
            current_lemma = lemmatize_ru(cw)
            if current_lemma in word_info and current_lemma not in added_lemmas:
                 info = word_info[current_lemma]
                 meanings = info.get("ko_meanings", [])
                 short_kr = "; ".join(meanings[:2])
                 rows.append({"lemma": current_lemma, "í•œêµ­ì–´ ëœ»": short_kr})
                 added_lemmas.add(current_lemma)

        # ë‚˜ë¨¸ì§€ ëˆ„ì ëœ ë‹¨ì–´ë“¤ì˜ lemma ì¶”ê°€
        all_lemmas = [lemmatize_ru(w) for w in selected]
        for lemma in all_lemmas:
            if lemma in word_info and lemma not in added_lemmas:
                info = word_info[lemma]
                meanings = info.get("ko_meanings", [])
                short_kr = "; ".join(meanings[:2])  # í•œë‘ ê°œë§Œ
                rows.append({"lemma": lemma, "í•œêµ­ì–´ ëœ»": short_kr})
                added_lemmas.add(lemma)

        if rows:
            df = pd.DataFrame(rows)
            st.dataframe(df, hide_index=True)

            csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ğŸ’¾ CSVë¡œ ì €ì¥í•˜ê¸°",
                data=csv_bytes,
                file_name="russian_words.csv",
                mime="text/csv",
            )
    else:
        st.caption("ë‹¨ì–´ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì´ê±°ë‚˜, ì•„ì§ ëœ»ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë§¨ ì•„ë˜ â€” ì§ì ‘ ë‹¨ì–´ ê²€ìƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.divider()
st.subheader("ğŸ” ì§ì ‘ ë‹¨ì–´ ê²€ìƒ‰")

manual = st.text_input("í…ìŠ¤íŠ¸ì™€ ìƒê´€ì—†ì´, ì§ì ‘ ë‹¨ì–´ë¥¼ ì…ë ¥í•´ ë¶„ì„í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.", "")

if manual:
    lemma = lemmatize_ru(manual)
    st.markdown(f"**ì…ë ¥ ë‹¨ì–´:** {manual}")
    st.markdown(f"**ê¸°ë³¸í˜•(lemma):** *{lemma}*")

    try:
        info = fetch_from_gemini(manual, lemma)
        ko_meanings = info.get("ko_meanings", [])
        examples = info.get("examples", [])
    except Exception as e:
        st.error(f"Gemini API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        ko_meanings = []
        examples = []

    # ì§ì ‘ ê²€ìƒ‰ìœ¼ë¡œ ê°€ì ¸ì˜¨ ê²ƒë„ word_infoì— ëˆ„ì 
    if ko_meanings:
        st.session_state.word_info[lemma] = {
            "lemma": lemma,
            "ko_meanings": ko_meanings,
        }
        # [ìˆ˜ì •] ì§ì ‘ ê²€ìƒ‰ ì‹œ selected_wordsì—ë„ ì¶”ê°€ (ì¹©ì— í‘œì‹œë˜ë„ë¡)
        if manual not in st.session_state.selected_words:
             st.session_state.selected_words.append(manual)

    if ko_meanings:
        st.markdown("**í•œêµ­ì–´ ëœ»:**")
        for m in ko_meanings:
            st.markdown(f"- {m}")

    if examples:
        st.markdown("### ğŸ“– ì˜ˆë¬¸")
        for ex in examples:
            ru = ex.get("ru", "")
            ko = ex.get("ko", "")
            if ru:
                st.markdown(f"- **{ru}**")
            if ko:
                st.markdown(f"â€ƒâ†’ {ko}")
