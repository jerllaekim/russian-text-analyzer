import streamlit as st
import re
import os
import json
import pandas as pd
from pymystem3 import Mystem
from google import genai
from google.cloud import vision 
import io
import urllib.parse 

# ---------------------- 0. ì´ˆê¸° ì„¤ì • ë° ì„¸ì…˜ ìƒíƒœ ----------------------

# ğŸŒŸ 1. êµì¬ ì—°ìŠµìš© í…ìŠ¤íŠ¸ ë°ì´í„° ì •ì˜
NEW_DEFAULT_TEXT = """ĞœĞĞ™ Ğ ĞĞ‘ĞĞ§Ğ˜Ğ™ Ğ”Ğ•ĞĞ¬
(Ğ Ğ°ÑÑĞºĞ°Ğ· ÑĞ¿Ğ¾Ğ½ÑĞºĞ¾Ğ³Ğ¾ Ğ±Ğ°Ğ½ĞºĞ¸Ñ€Ğ°)
Ğ Ğ°Ğ·Ñ€ĞµÑˆĞ¸Ñ‚Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒcÑ. ĞœĞµĞ½Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ Ğ¢Ğ°ĞºĞµÑˆĞ¸ ĞÑĞ°Ğ´Ğ°. Ğ¯ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ Ğ² Ğ±Ğ°Ğ½ĞºĞµ Â«Ğ¡Ğ°ĞºÑƒÑ€Ğ°Â». Ğ¯ Ğ¶Ğ¸Ğ²Ñƒ Ğ½ĞµĞ´Ğ°Ğ»ĞµĞºĞ¾ Ğ¾Ñ‚ Ğ¢Ğ¾ĞºĞ¸Ğ¾, Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ² Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğµ Ğ´Ğ½Ğ¸ Ñ Ğ²ÑÑ‚Ğ°Ñ Ğ² 5 Ñ‡Ğ°ÑĞ¾Ğ² ÑƒÑ‚Ñ€Ğ°, ÑƒĞ¼Ñ‹Ğ²Ğ°ÑÑÑŒ, Ğ¾Ğ´ĞµĞ²Ğ°ÑÑÑŒ, Ğ·Ğ°Ğ²Ñ‚Ñ€Ğ°ĞºĞ°Ñ Ğ¸ Ğ¸Ğ´Ñƒ Ğ½Ğ° ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ñ. ĞĞ° ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ğ¸ Ñ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ ÑĞ²ĞµĞ¶ÑƒÑ Ğ³Ğ°Ğ·ĞµÑ‚Ñƒ. Ğ¯ ĞµĞ´Ñƒ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğ° ÑĞ»ĞµĞºÑ‚Ñ€Ğ¸Ñ‡ĞºĞµ. Ğ’ ÑĞ»ĞµĞºÑ‚Ñ€Ğ¸Ñ‡ĞºĞµ Ñ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ñ‡Ğ¸Ñ‚Ğ°Ñ Ğ¸Ğ»Ğ¸ ÑĞ¿Ğ»Ñ. Ğ”Ğ¾Ñ€Ğ¾Ğ³Ğ° Ğ¾Ñ‚ Ğ´Ğ¾Ğ¼Ğ° Ğ´Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚ 2 Ñ‡Ğ°ÑĞ°.
Ğ‘Ğ°Ğ½Ğº Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ² 8 ÑƒÑ‚Ñ€Ğ°, Ğ° Ğ·Ğ°ĞºĞ°Ğ½Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ² 8 Ğ²ĞµÑ‡ĞµÑ€Ğ°, Ñ‚Ğ¾ ĞµÑÑ‚ÑŒ Ğ¼Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ Ğ´ĞµĞ½ÑŒ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµÑ‚ÑÑ 12 Ñ‡Ğ°ÑĞ¾Ğ², Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ 2 Ğ¿ĞµÑ€ĞµÑ€Ñ‹Ğ²Ğ°. Ğ Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ Ğ´ĞµĞ½ÑŒ Ğ´Ğ»Ñ Ğ¶ĞµĞ½Ñ‰Ğ¸Ğ½, ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ğ¾, Ğ¼ĞµĞ½ÑŒÑˆĞµ.
Ğ’ 8:30 Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ ÑĞ¾Ğ±Ñ€Ğ°Ğ½Ğ¸Ğµ, Ğ³Ğ´Ğµ Ğ¼Ñ‹ Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°ĞµĞ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºÑƒÑ ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸Ñ, ĞºÑƒÑ€Ñ Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€Ğ°, Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸, Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ğ½Ğ° Ğ´ĞµĞ½ÑŒ. ĞŸĞ¾Ñ‚Ğ¾Ğ¼ Ñ Ñ‡Ğ¸Ñ‚Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹, Ñ€ĞµÑˆĞ°Ñ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ÑÑÑŒ Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸, Ğ¾Ñ‚ĞºÑ€Ñ‹Ğ²Ğ°Ñ Ğ¸Ğ¼ ÑÑ‡Ñ‘Ñ‚ Ğ² Ğ±Ğ°Ğ½ĞºĞµ, Ğ´Ğ°Ñ Ğ¸Ğ¼ ĞºÑ€ĞµĞ´Ğ¸Ñ‚, Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ°Ñ€Ğ¸Ğ²Ğ°Ñ Ğ¿Ğ¾ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ñƒ Ğ¸ Ñ‚Ğ°Ğº Ğ´Ğ°Ğ»ĞµĞµ.
ĞŸĞ¾ÑĞ»Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ÑÑÑŒ Ğ´Ğ¾Ğ¼Ğ¾Ğ¹. Ğ¢Ğ°Ğº ĞºĞ°Ğº Ñ Ğ¾Ñ‡ĞµĞ½ÑŒ ÑƒÑÑ‚Ğ°Ñ, Ğ´Ğ¾Ğ¼Ğ° Ñ ÑÑ€Ğ°Ğ·Ñƒ Ğ»Ğ¾Ğ¶ÑƒÑÑŒ ÑĞ¿Ğ°Ñ‚ÑŒ."""

DEFAULT_TEST_TEXT = "Ğ§ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ ÑƒĞ»Ğ¸Ñ†Ğµ. Ğ­Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°. Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾. Ğ¯ Ñ‡Ğ°ÑÑ‚Ğ¾ Ñ‡Ğ¸Ñ‚Ğ°Ñ ÑÑ‚Ñƒ ĞºĞ½Ğ¸Ğ³Ñƒ."


st.set_page_config(page_title="ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°", layout="wide")
st.title("ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ê¸°") 

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "selected_words" not in st.session_state:
    st.session_state.selected_words = []
if "clicked_word" not in st.session_state:
    st.session_state.clicked_word = None
if "word_info" not in st.session_state:
    st.session_state.word_info = {}
if "current_search_query" not in st.session_state:
    st.session_state.current_search_query = ""
if "ocr_output_text" not in st.session_state:
    st.session_state.ocr_output_text = ""
if "input_text_area" not in st.session_state:
    st.session_state.input_text_area = DEFAULT_TEST_TEXT
if "translated_text" not in st.session_state:
    st.session_state.translated_text = ""
if "last_processed_text" not in st.session_state:
    st.session_state.last_processed_text = "" 
if "last_processed_query" not in st.session_state:
    st.session_state.last_processed_query = ""


mystem = Mystem()

# ---------------------- í’ˆì‚¬ ë³€í™˜ ë”•ì…”ë„ˆë¦¬ ë° Mystem í•¨ìˆ˜ ----------------------
POS_MAP = {
    'S': 'ëª…ì‚¬', 'V': 'ë™ì‚¬', 'A': 'í˜•ìš©ì‚¬', 'ADV': 'ë¶€ì‚¬', 'PR': 'ì „ì¹˜ì‚¬',
    'CONJ': 'ì ‘ì†ì‚¬', 'INTJ': 'ê°íƒ„ì‚¬', 'PART': 'ë¶ˆë³€í™”ì‚¬', 'NUM': 'ìˆ˜ì‚¬',
    'APRO': 'ëŒ€ëª…ì‚¬ì  í˜•ìš©ì‚¬', 'ANUM': 'ì„œìˆ˜ì‚¬', 'SPRO': 'ëŒ€ëª…ì‚¬',
}

@st.cache_data(show_spinner=False)
def lemmatize_ru(word: str) -> str:
    if ' ' in word.strip():
        return word.strip()
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        lemmas = mystem.lemmatize(word)
        return (lemmas[0] if lemmas else word).strip()
    return word

@st.cache_data(show_spinner=False)
def get_pos_ru(word: str) -> str:
    if ' ' in word.strip():
        return 'ê´€ìš©êµ¬'
    if re.fullmatch(r'\w+', word, flags=re.UNICODE):
        analysis = mystem.analyze(word)
        if analysis and 'analysis' in analysis[0] and analysis[0]['analysis']:
            grammar_info = analysis[0]['analysis'][0]['gr']
            pos_abbr = grammar_info.split('=')[0].split(',')[0].strip()
            return POS_MAP.get(pos_abbr, 'í’ˆì‚¬')
    return 'í’ˆì‚¬'

# ---------------------- OCR í•¨ìˆ˜ ----------------------
@st.cache_data(show_spinner="ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘")
def detect_text_from_image(image_bytes):
    try:
        if st.secrets.get("GCP_SA_KEY"):
            with open("temp_sa_key.json", "w") as f:
                json.dump(st.secrets["GCP_SA_KEY"], f)
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "temp_sa_key.json"
        elif "GOOGLE_APPLICATION_CREDENTIALS" not in os.environ:
            return "OCR API í‚¤(GOOGLE_APPLICATION_CREDENTIALS)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Cloud Vision API ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

        client = vision.ImageAnnotatorClient()
        image = vision.Image(content=image_bytes)
        response = client.text_detection(image=image)
        texts = response.text
        
        if response.error.message:
            return f"Vision API ì˜¤ë¥˜: {response.error.message}"
            
        return texts.split('\n', 1)[0] if texts else "ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    except Exception as e:
        return f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# ---------------------- 1. Gemini ì—°ë™ í•¨ìˆ˜ ----------------------

def get_gemini_client():
    api_key = st.secrets.get("GEMINI_API_KEY", os.getenv("GEMINI_API_KEY"))
    return genai.Client(api_key=api_key) if api_key else None

@st.cache_data(show_spinner=False)
def fetch_from_gemini(word, lemma, pos):
    client = get_gemini_client()
    if not client:
        return {"ko_meanings": [f"'{word}'ì˜ API í‚¤ ì—†ìŒ (GEMINI_API_KEY ì„¤ì • í•„ìš”)"], "examples": []}
    
    SYSTEM_PROMPT = "ë„ˆëŠ” ëŸ¬ì‹œì•„ì–´-í•œêµ­ì–´ í•™ìŠµ ë„ìš°ë¯¸ì´ë‹¤. ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´ì— ëŒ€í•´ ê°„ë‹¨í•œ í•œêµ­ì–´ ëœ»ê³¼ ì˜ˆë¬¸ì„ ìµœëŒ€ ë‘ ê°œë§Œ ì œê³µí•œë‹¤. í•œêµ­ì–´ ëœ»ì„ ì œê³µí•  ë•Œ ê²© ì •ë³´, ë¬¸ë²• ì •ë³´ ë“± ë¶ˆí•„ìš”í•œ ë¶€ê°€ ì •ë³´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤. ë§Œì•½ ë™ì‚¬(V)ì´ë©´, ë¶ˆì™„ë£Œìƒ(imp)ê³¼ ì™„ë£Œìƒ(perf) í˜•íƒœë¥¼ í•¨ê»˜ ì œê³µí•´ì•¼ í•œë‹¤. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤."
    
    if pos == 'ë™ì‚¬':
        prompt = f"""{SYSTEM_PROMPT}
ë‹¨ì–´: {word}
ê¸°ë³¸í˜•: {lemma}
{{ "ko_meanings": ["ëœ»1", "ëœ»2"], "aspect_pair": {{"imp": "ë¶ˆì™„ë£Œìƒ ë™ì‚¬", "perf": "ì™„ë£Œìƒ ë™ì‚¬"}}, "examples": [ {{"ru": "ì˜ˆë¬¸1", "ko": "ë²ˆì—­1"}}, {{"ru": "ì˜ˆë¬¸2", "ko": "ë²ˆì—­2"}} ] }}
"""
    else:
        prompt = f"""{SYSTEM_PROMPT}
ë‹¨ì–´: {word}
ê¸°ë³¸í˜•: {lemma}
{{ "ko_meanings": ["ëœ»1", "ëœ»2"], "examples": [ {{"ru": "ì˜ˆë¬¸1", "ko": "ë²ˆì—­1"}}, {{"ru": "ì˜ˆë¬¸2", "ko": "ë²ˆì—­2"}} ] }}
"""
    
    res = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
    text = res.text.strip()
    
    try:
        # JSON íŒŒì‹± ë¡œì§
        if text.startswith("```"):
            text = text.strip("`")
            lines = text.splitlines()
            if lines and lines[0].lower().startswith("json"):
                text = "\n".join(lines[1:])
            elif lines:
                text = "\n".join(lines)
                
        start_index = text.find('{')
        end_index = text.rfind('}')
        
        if start_index != -1 and end_index != -1 and end_index > start_index:
            json_text = text[start_index : end_index + 1]
        else:
            json_text = text
            
        data = json.loads(json_text)
        
        if 'examples' in data and len(data['examples']) > 2:
            data['examples'] = data['examples'][:2]
        return data
        
    except json.JSONDecodeError:
        return {"ko_meanings": ["JSON íŒŒì‹± ì˜¤ë¥˜"], "examples": []}

# ---------------------- 2. í…ìŠ¤íŠ¸ ë²ˆì—­ í•¨ìˆ˜ ----------------------

@st.cache_data(show_spinner="í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì¤‘...")
def translate_text(russian_text, highlight_words):
    client = get_gemini_client()
    if not client:
        return "Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë²ˆì—­ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    phrases_to_highlight = ", ".join([f"'{w}'" for w in highlight_words])
    
    SYSTEM_INSTRUCTION = '''ë„ˆëŠ” ë²ˆì—­ê°€ì´ë‹¤. ìš”ì²­ëœ ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ë¥¼ ë¬¸ë§¥ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³ , ì ˆëŒ€ë¡œ ë‹¤ë¥¸ ì„¤ëª…, ì˜µì…˜, ì§ˆë¬¸, ë¶€ê°€ì ì¸ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤. ì˜¤ì§ ìµœì¢… ë²ˆì—­ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•œë‹¤.'''

    if phrases_to_highlight:
        translation_prompt = f"""
        **ë°˜ë“œì‹œ ì•„ë˜ ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´/êµ¬ì˜ í•œêµ­ì–´ ë²ˆì—­ì´ ë“±ì¥í•˜ë©´, ê·¸ í•œêµ­ì–´ ë²ˆì—­ ë‹¨ì–´/êµ¬ë¥¼ `<PHRASE_START>`ì™€ `<PHRASE_END>` ë§ˆí¬ì—…ìœ¼ë¡œ ê°ì‹¸ì•¼ í•´.**

        ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸: '{russian_text}'
        ë§ˆí¬ì—… ëŒ€ìƒ ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´/êµ¬: {phrases_to_highlight}
        """
    else:
        translation_prompt = f"ì›ë³¸ ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸: '{russian_text}'"

    try:
        res = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=translation_prompt,
            config={"system_instruction": SYSTEM_INSTRUCTION}
        )
        translated = res.text.strip()
        
        # í›„ì²˜ë¦¬: ë§ˆí¬ì—…ì„ HTML Span íƒœê·¸ë¡œ ë³€í™˜
        selected_class = "word-selected"
        translated = translated.replace("<PHRASE_START>", f'<span class="{selected_class}">')
        translated = translated.replace("<PHRASE_END>", '</span>')

        return translated

    except Exception as e:
        return f"ë²ˆì—­ ì˜¤ë¥˜ ë°œìƒ: {e}"


# ---------------------- 3. ì „ì—­ ìŠ¤íƒ€ì¼ ì •ì˜ ----------------------

st.markdown("""
<style>
    /* í…ìŠ¤íŠ¸ ì˜ì—­ ê°€ë…ì„± */
    .text-container {
        line-height: 2.0;
        margin-bottom: 20px;
        font-size: 1.25em;
    }
    /* ì„ íƒ/ê²€ìƒ‰ëœ ë‹¨ì–´/êµ¬ í•˜ì´ë¼ì´íŒ… + ë°‘ì¤„ */
    .word-selected {
        color: #007bff !important; 
        font-weight: bold;
        background-color: #e0f0ff; 
        padding: 2px 0px;
        border-bottom: 3px solid #007bff; 
        border-radius: 2px;
    }
    .search-link-container {
        display: flex;
        gap: 10px;
        margin-top: 15px;
        flex-wrap: wrap;
    }
</style>
""", unsafe_allow_html=True)


# ğŸŒŸ 4. ë²„íŠ¼ í´ë¦­ ì‹œ í…ìŠ¤íŠ¸ë¥¼ ë¡œë“œí•˜ëŠ” ì½œë°± í•¨ìˆ˜ ì •ì˜
def load_default_text():
    st.session_state.input_text_area = NEW_DEFAULT_TEXT 
    st.session_state.translated_text = ""
    st.session_state.selected_words = []
    st.session_state.clicked_word = None
    st.session_state.word_info = {}
    st.session_state.current_search_query = ""
    st.session_state.last_processed_query = ""


# ---------------------- 4. UI ë°°ì¹˜ ë° ë©”ì¸ ë¡œì§ ----------------------

# --- 4.1. OCR ë° í…ìŠ¤íŠ¸ ì…ë ¥ ì„¹ì…˜ ---
st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ(ì—…ë°ì´íŠ¸ ì˜ˆì •)")
uploaded_file = st.file_uploader("JPG, PNG ë“± ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image_bytes = uploaded_file.getvalue()
    ocr_result = detect_text_from_image(image_bytes)
    
    if ocr_result and not ocr_result.startswith(("OCR API í‚¤", "Vision API ì˜¤ë¥˜")):
        st.session_state.ocr_output_text = ocr_result
        st.session_state.input_text_area = ocr_result
        st.session_state.translated_text = ""
        st.success("ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
    else:
        st.error(ocr_result)

# ğŸŒŸ 5. í…ìŠ¤íŠ¸ ë°˜ì˜ ë²„íŠ¼ ì¶”ê°€
st.button(
    "ğŸ“š ì¤‘ê¸‰ëŸ¬ì‹œì•„ì–´ì—°ìŠµ í…ìŠ¤íŠ¸ ë°˜ì˜í•˜ê¸°", 
    on_click=load_default_text, 
    help="êµì¬ ì—°ìŠµìš© í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ì°½ì— ë°˜ì˜í•©ë‹ˆë‹¤."
)

st.subheader("ğŸ“ ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸") 
current_text = st.text_area(
    "ëŸ¬ì‹œì•„ì–´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ìœ„ì— ì—…ë¡œë“œëœ í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”", 
    value=st.session_state.input_text_area, 
    height=150, 
    key="input_text_area"
)


# í…ìŠ¤íŠ¸ê°€ ìˆ˜ì •ë˜ë©´ ìƒíƒœ ì—…ë°ì´íŠ¸ ë° ë²ˆì—­/ë¶„ì„ ìƒíƒœ ì´ˆê¸°í™”
if current_text != st.session_state.last_processed_text:
    st.session_state.translated_text = ""
    st.session_state.selected_words = []
    st.session_state.clicked_word = None
    st.session_state.word_info = {}
    st.session_state.current_search_query = ""

# --- 4.2. ë‹¨ì–´ ê²€ìƒ‰ì°½ ë° ë¡œì§ ---
st.divider()
st.subheader("ğŸ” ë‹¨ì–´/êµ¬ ê²€ìƒ‰") 
manual_input = st.text_input("ë‹¨ì–´ ë˜ëŠ” êµ¬ë¥¼ ì…ë ¥í•˜ê³  Enter (ì˜ˆ: 'Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ ÑƒĞ»Ğ¸Ñ†Ğµ')", key="current_search_query")

if manual_input and manual_input != st.session_state.get("last_processed_query"):
    if manual_input not in st.
